{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BYOLSingleScript.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/deepmind/dm-haiku\n",
        "!pip install optax\n",
        "#!pip install jax==0.2.11\n",
        "!pip install dm-acme\n",
        "!dm-tree\n",
        "#!pip install jax\n",
        "#!pip install -U jaxlib\n",
        "#numpy>=1.16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y15mQQf6BPoc",
        "outputId": "abf45087-d229-4f92-84c3-14034b3078ca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepmind/dm-haiku\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-25ci6yfa\n",
            "  Running command git clone -q https://github.com/deepmind/dm-haiku /tmp/pip-req-build-25ci6yfa\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.7.dev0) (1.0.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.7.dev0) (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.7.dev0) (1.21.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.7.dev0) (0.8.9)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.7.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku==0.0.7.dev0) (1.15.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.1)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.4)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.5)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.2+cuda11.cudnn805)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->optax) (1.15.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.2)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.6)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
            "Requirement already satisfied: dm-acme in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: dm-env in /usr/local/lib/python3.7/dist-packages (from dm-acme) (1.5)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-acme) (0.1.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from dm-acme) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dm-acme) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-acme) (3.10.0.2)\n",
            "Requirement already satisfied: dm-launchpad==0.5.0 in /usr/local/lib/python3.7/dist-packages (from dm-acme) (0.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from dm-acme) (7.1.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from dm-launchpad==0.5.0->dm-acme) (3.17.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from dm-launchpad==0.5.0->dm-acme) (1.3.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from dm-launchpad==0.5.0->dm-acme) (4.0.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from dm-launchpad==0.5.0->dm-acme) (1.1.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.7/dist-packages (from dm-launchpad==0.5.0->dm-acme) (1.44.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from dm-launchpad==0.5.0->dm-acme) (5.4.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from dm-launchpad==0.5.0->dm-acme) (1.3.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->dm-acme) (1.15.0)\n",
            "/bin/bash: dm-tree: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "CgzFCYqM85Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Utility functions.\"\"\"\n",
        "\n",
        "from typing import Optional, Text\n",
        "from absl import logging\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "def topk_accuracy(\n",
        "    logits: jnp.ndarray,\n",
        "    labels: jnp.ndarray,\n",
        "    topk: int,\n",
        "    ignore_label_above: Optional[int] = None,\n",
        ") -> jnp.ndarray:\n",
        "  \"\"\"Top-num_codes accuracy.\"\"\"\n",
        "  assert len(labels.shape) == 1, 'topk expects 1d int labels.'\n",
        "  assert len(logits.shape) == 2, 'topk expects 2d logits.'\n",
        "\n",
        "  if ignore_label_above is not None:\n",
        "    logits = logits[labels < ignore_label_above, :]\n",
        "    labels = labels[labels < ignore_label_above]\n",
        "\n",
        "  prds = jnp.argsort(logits, axis=1)[:, ::-1]\n",
        "  prds = prds[:, :topk]\n",
        "  total = jnp.any(prds == jnp.tile(labels[:, jnp.newaxis], [1, topk]), axis=1)\n",
        "\n",
        "  return total\n",
        "\n",
        "\n",
        "def softmax_cross_entropy(\n",
        "    logits: jnp.ndarray,\n",
        "    labels: jnp.ndarray,\n",
        "    reduction: Optional[Text] = 'mean',\n",
        ") -> jnp.ndarray:\n",
        "  \"\"\"Computes softmax cross entropy given logits and one-hot class labels.\n",
        "\n",
        "  Args:\n",
        "    logits: Logit output values.\n",
        "    labels: Ground truth one-hot-encoded labels.\n",
        "    reduction: Type of reduction to apply to loss.\n",
        "\n",
        "  Returns:\n",
        "    Loss value. If `reduction` is `none`, this has the same shape as `labels`;\n",
        "    otherwise, it is scalar.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If the type of `reduction` is unsupported.\n",
        "  \"\"\"\n",
        "  loss = -jnp.sum(labels * jax.nn.log_softmax(logits), axis=-1)\n",
        "  if reduction == 'sum':\n",
        "    return jnp.sum(loss)\n",
        "  elif reduction == 'mean':\n",
        "    return jnp.mean(loss)\n",
        "  elif reduction == 'none' or reduction is None:\n",
        "    return loss\n",
        "  else:\n",
        "    raise ValueError(f'Incorrect reduction mode {reduction}')\n",
        "\n",
        "\n",
        "def l2_normalize(\n",
        "    x: jnp.ndarray,\n",
        "    axis: Optional[int] = None,\n",
        "    epsilon: float = 1e-12,\n",
        ") -> jnp.ndarray:\n",
        "  \"\"\"l2 normalize a tensor on an axis with numerical stability.\"\"\"\n",
        "  square_sum = jnp.sum(jnp.square(x), axis=axis, keepdims=True)\n",
        "  x_inv_norm = jax.lax.rsqrt(jnp.maximum(square_sum, epsilon))\n",
        "  return x * x_inv_norm\n",
        "\n",
        "\n",
        "def l2_weight_regularizer(params):\n",
        "  \"\"\"Helper to do lasso on weights.\n",
        "\n",
        "  Args:\n",
        "    params: the entire param set.\n",
        "\n",
        "  Returns:\n",
        "    Scalar of the l2 norm of the weights.\n",
        "  \"\"\"\n",
        "  l2_norm = 0.\n",
        "  for mod_name, mod_params in params.items():\n",
        "    if 'norm' not in mod_name:\n",
        "      for param_k, param_v in mod_params.items():\n",
        "        if param_k != 'b' not in param_k:  # Filter out biases\n",
        "          l2_norm += jnp.sum(jnp.square(param_v))\n",
        "        else:\n",
        "          logging.warning('Excluding %s/%s from optimizer weight decay!',\n",
        "                          mod_name, param_k)\n",
        "    else:\n",
        "      logging.warning('Excluding %s from optimizer weight decay!', mod_name)\n",
        "\n",
        "  return 0.5 * l2_norm\n",
        "\n",
        "\n",
        "def regression_loss(x: jnp.ndarray, y: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Byol's regression loss. This is a simple cosine similarity.\"\"\"\n",
        "  normed_x, normed_y = l2_normalize(x, axis=-1), l2_normalize(y, axis=-1)\n",
        "  return jnp.sum((normed_x - normed_y)**2, axis=-1)\n",
        "\n",
        "\n",
        "def bcast_local_devices(value):\n",
        "  \"\"\"Broadcasts an object to all local devices.\"\"\"\n",
        "  devices = jax.local_devices()\n",
        "\n",
        "  def _replicate(x):\n",
        "    \"\"\"Replicate an object on each device.\"\"\"\n",
        "    x = jnp.array(x)\n",
        "    return jax.device_put_sharded(len(devices) * [x], devices)\n",
        "\n",
        "  return jax.tree_util.tree_map(_replicate, value)\n",
        "\n",
        "\n",
        "def get_first(xs):\n",
        "  \"\"\"Gets values from the first device.\"\"\"\n",
        "  return jax.tree_map(lambda x: x[0], xs)\n"
      ],
      "metadata": {
        "id": "VvapfqRP9wX-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Data preprocessing and augmentation.\"\"\"\n",
        "\n",
        "import functools\n",
        "from typing import Any, Mapping, Text\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# typing\n",
        "JaxBatch = Mapping[Text, jnp.ndarray]\n",
        "ConfigDict = Mapping[Text, Any]\n",
        "\n",
        "augment_config = dict(\n",
        "    view1=dict(\n",
        "        random_flip=True,  # Random left/right flip\n",
        "        color_transform=dict(\n",
        "            apply_prob=1.0,\n",
        "            # Range of jittering\n",
        "            brightness=0.4,\n",
        "            contrast=0.4,\n",
        "            saturation=0.2,\n",
        "            hue=0.1,\n",
        "            # Probability of applying color jittering\n",
        "            color_jitter_prob=0.8,\n",
        "            # Probability of converting to grayscale\n",
        "            to_grayscale_prob=0.2,\n",
        "            # Shuffle the order of color transforms\n",
        "            shuffle=True),\n",
        "        gaussian_blur=dict(\n",
        "            apply_prob=1.0,\n",
        "            # Kernel size ~ image_size / blur_divider\n",
        "            blur_divider=10.,\n",
        "            # Kernel distribution\n",
        "            sigma_min=0.1,\n",
        "            sigma_max=2.0),\n",
        "        solarize=dict(apply_prob=0.0, threshold=0.5),\n",
        "    ),\n",
        "    view2=dict(\n",
        "        random_flip=True,\n",
        "        color_transform=dict(\n",
        "            apply_prob=1.0,\n",
        "            brightness=0.4,\n",
        "            contrast=0.4,\n",
        "            saturation=0.2,\n",
        "            hue=0.1,\n",
        "            color_jitter_prob=0.8,\n",
        "            to_grayscale_prob=0.2,\n",
        "            shuffle=True),\n",
        "        gaussian_blur=dict(\n",
        "            apply_prob=0.1, blur_divider=10., sigma_min=0.1, sigma_max=2.0),\n",
        "        solarize=dict(apply_prob=0.2, threshold=0.5),\n",
        "    ))\n",
        "\n",
        "\n",
        "def postprocess(inputs: JaxBatch, rng: jnp.ndarray):\n",
        "  \"\"\"Apply the image augmentations to crops in inputs (view1 and view2).\"\"\"\n",
        "\n",
        "  def _postprocess_image(\n",
        "      images: jnp.ndarray,\n",
        "      rng: jnp.ndarray,\n",
        "      presets: ConfigDict,\n",
        "  ) -> JaxBatch:\n",
        "    \"\"\"Applies augmentations in post-processing.\n",
        "\n",
        "    Args:\n",
        "      images: an NHWC tensor (with C=3), with float values in [0, 1].\n",
        "      rng: a single PRNGKey.\n",
        "      presets: a dict of presets for the augmentations.\n",
        "\n",
        "    Returns:\n",
        "      A batch of augmented images with shape NHWC, with keys view1, view2\n",
        "      and labels.\n",
        "    \"\"\"\n",
        "    flip_rng, color_rng, blur_rng, solarize_rng = jax.random.split(rng, 4)\n",
        "    out = images\n",
        "    if presets['random_flip']:\n",
        "      out = random_flip(out, flip_rng)\n",
        "    if presets['color_transform']['apply_prob'] > 0:\n",
        "      out = color_transform(out, color_rng, **presets['color_transform'])\n",
        "    if presets['gaussian_blur']['apply_prob'] > 0:\n",
        "      out = gaussian_blur(out, blur_rng, **presets['gaussian_blur'])\n",
        "    if presets['solarize']['apply_prob'] > 0:\n",
        "      out = solarize(out, solarize_rng, **presets['solarize'])\n",
        "    out = jnp.clip(out, 0., 1.)\n",
        "    return jax.lax.stop_gradient(out)\n",
        "\n",
        "  rng1, rng2 = jax.random.split(rng, num=2)\n",
        "  view1 = _postprocess_image(inputs['view1'], rng1, augment_config['view1'])\n",
        "  view2 = _postprocess_image(inputs['view2'], rng2, augment_config['view2'])\n",
        "  return dict(view1=view1, view2=view2, labels=inputs['labels'])\n",
        "\n",
        "\n",
        "def _maybe_apply(apply_fn, inputs, rng, apply_prob):\n",
        "  should_apply = jax.random.uniform(rng, shape=()) <= apply_prob\n",
        "  return jax.lax.cond(should_apply, inputs, apply_fn, inputs, lambda x: x)\n",
        "\n",
        "\n",
        "def _depthwise_conv2d(inputs, kernel, strides, padding):\n",
        "  \"\"\"Computes a depthwise conv2d in Jax.\n",
        "\n",
        "  Args:\n",
        "    inputs: an NHWC tensor with N=1.\n",
        "    kernel: a [H\", W\", 1, C] tensor.\n",
        "    strides: a 2d tensor.\n",
        "    padding: \"SAME\" or \"VALID\".\n",
        "\n",
        "  Returns:\n",
        "    The depthwise convolution of inputs with kernel, as [H, W, C].\n",
        "  \"\"\"\n",
        "  return jax.lax.conv_general_dilated(\n",
        "      inputs,\n",
        "      kernel,\n",
        "      strides,\n",
        "      padding,\n",
        "      feature_group_count=inputs.shape[-1],\n",
        "      dimension_numbers=('NHWC', 'HWIO', 'NHWC'))\n",
        "\n",
        "\n",
        "def _gaussian_blur_single_image(image, kernel_size, padding, sigma):\n",
        "  \"\"\"Applies gaussian blur to a single image, given as NHWC with N=1.\"\"\"\n",
        "  radius = int(kernel_size / 2)\n",
        "  kernel_size_ = 2 * radius + 1\n",
        "  x = jnp.arange(-radius, radius + 1).astype(jnp.float32)\n",
        "  blur_filter = jnp.exp(-x**2 / (2. * sigma**2))\n",
        "  blur_filter = blur_filter / jnp.sum(blur_filter)\n",
        "  blur_v = jnp.reshape(blur_filter, [kernel_size_, 1, 1, 1])\n",
        "  blur_h = jnp.reshape(blur_filter, [1, kernel_size_, 1, 1])\n",
        "  num_channels = image.shape[-1]\n",
        "  blur_h = jnp.tile(blur_h, [1, 1, 1, num_channels])\n",
        "  blur_v = jnp.tile(blur_v, [1, 1, 1, num_channels])\n",
        "  expand_batch_dim = len(image.shape) == 3\n",
        "  if expand_batch_dim:\n",
        "    image = image[jnp.newaxis, ...]\n",
        "  blurred = _depthwise_conv2d(image, blur_h, strides=[1, 1], padding=padding)\n",
        "  blurred = _depthwise_conv2d(blurred, blur_v, strides=[1, 1], padding=padding)\n",
        "  blurred = jnp.squeeze(blurred, axis=0)\n",
        "  return blurred\n",
        "\n",
        "\n",
        "def _random_gaussian_blur(image, rng, kernel_size, padding, sigma_min,\n",
        "                          sigma_max, apply_prob):\n",
        "  \"\"\"Applies a random gaussian blur.\"\"\"\n",
        "  apply_rng, transform_rng = jax.random.split(rng)\n",
        "\n",
        "  def _apply(image):\n",
        "    sigma_rng, = jax.random.split(transform_rng, 1)\n",
        "    sigma = jax.random.uniform(\n",
        "        sigma_rng,\n",
        "        shape=(),\n",
        "        minval=sigma_min,\n",
        "        maxval=sigma_max,\n",
        "        dtype=jnp.float32)\n",
        "    return _gaussian_blur_single_image(image, kernel_size, padding, sigma)\n",
        "\n",
        "  return _maybe_apply(_apply, image, apply_rng, apply_prob)\n",
        "\n",
        "\n",
        "def rgb_to_hsv(r, g, b):\n",
        "  \"\"\"Converts R, G, B  values to H, S, V values.\n",
        "\n",
        "  Reference TF implementation:\n",
        "  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/adjust_saturation_op.cc\n",
        "  Only input values between 0 and 1 are guaranteed to work properly, but this\n",
        "  function complies with the TF implementation outside of this range.\n",
        "\n",
        "  Args:\n",
        "    r: A tensor representing the red color component as floats.\n",
        "    g: A tensor representing the green color component as floats.\n",
        "    b: A tensor representing the blue color component as floats.\n",
        "\n",
        "  Returns:\n",
        "    H, S, V values, each as tensors of shape [...] (same as the input without\n",
        "    the last dimension).\n",
        "  \"\"\"\n",
        "  vv = jnp.maximum(jnp.maximum(r, g), b)\n",
        "  range_ = vv - jnp.minimum(jnp.minimum(r, g), b)\n",
        "  sat = jnp.where(vv > 0, range_ / vv, 0.)\n",
        "  norm = jnp.where(range_ != 0, 1. / (6. * range_), 1e9)\n",
        "\n",
        "  hr = norm * (g - b)\n",
        "  hg = norm * (b - r) + 2. / 6.\n",
        "  hb = norm * (r - g) + 4. / 6.\n",
        "\n",
        "  hue = jnp.where(r == vv, hr, jnp.where(g == vv, hg, hb))\n",
        "  hue = hue * (range_ > 0)\n",
        "  hue = hue + (hue < 0)\n",
        "\n",
        "  return hue, sat, vv\n",
        "\n",
        "\n",
        "def hsv_to_rgb(h, s, v):\n",
        "  \"\"\"Converts H, S, V values to an R, G, B tuple.\n",
        "\n",
        "  Reference TF implementation:\n",
        "  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/adjust_saturation_op.cc\n",
        "  Only input values between 0 and 1 are guaranteed to work properly, but this\n",
        "  function complies with the TF implementation outside of this range.\n",
        "\n",
        "  Args:\n",
        "    h: A float tensor of arbitrary shape for the hue (0-1 values).\n",
        "    s: A float tensor of the same shape for the saturation (0-1 values).\n",
        "    v: A float tensor of the same shape for the value channel (0-1 values).\n",
        "\n",
        "  Returns:\n",
        "    An (r, g, b) tuple, each with the same dimension as the inputs.\n",
        "  \"\"\"\n",
        "  c = s * v\n",
        "  m = v - c\n",
        "  dh = (h % 1.) * 6.\n",
        "  fmodu = dh % 2.\n",
        "  x = c * (1 - jnp.abs(fmodu - 1))\n",
        "  hcat = jnp.floor(dh).astype(jnp.int32)\n",
        "  rr = jnp.where(\n",
        "      (hcat == 0) | (hcat == 5), c, jnp.where(\n",
        "          (hcat == 1) | (hcat == 4), x, 0)) + m\n",
        "  gg = jnp.where(\n",
        "      (hcat == 1) | (hcat == 2), c, jnp.where(\n",
        "          (hcat == 0) | (hcat == 3), x, 0)) + m\n",
        "  bb = jnp.where(\n",
        "      (hcat == 3) | (hcat == 4), c, jnp.where(\n",
        "          (hcat == 2) | (hcat == 5), x, 0)) + m\n",
        "  return rr, gg, bb\n",
        "\n",
        "\n",
        "def adjust_brightness(rgb_tuple, delta):\n",
        "  return jax.tree_map(lambda x: x + delta, rgb_tuple)\n",
        "\n",
        "\n",
        "def adjust_contrast(image, factor):\n",
        "  def _adjust_contrast_channel(channel):\n",
        "    mean = jnp.mean(channel, axis=(-2, -1), keepdims=True)\n",
        "    return factor * (channel - mean) + mean\n",
        "  return jax.tree_map(_adjust_contrast_channel, image)\n",
        "\n",
        "\n",
        "def adjust_saturation(h, s, v, factor):\n",
        "  return h, jnp.clip(s * factor, 0., 1.), v\n",
        "\n",
        "\n",
        "def adjust_hue(h, s, v, delta):\n",
        "  # Note: this method exactly matches TF\"s adjust_hue (combined with the hsv/rgb\n",
        "  # conversions) when running on GPU. When running on CPU, the results will be\n",
        "  # different if all RGB values for a pixel are outside of the [0, 1] range.\n",
        "  return (h + delta) % 1.0, s, v\n",
        "\n",
        "\n",
        "def _random_brightness(rgb_tuple, rng, max_delta):\n",
        "  delta = jax.random.uniform(rng, shape=(), minval=-max_delta, maxval=max_delta)\n",
        "  return adjust_brightness(rgb_tuple, delta)\n",
        "\n",
        "\n",
        "def _random_contrast(rgb_tuple, rng, max_delta):\n",
        "  factor = jax.random.uniform(\n",
        "      rng, shape=(), minval=1 - max_delta, maxval=1 + max_delta)\n",
        "  return adjust_contrast(rgb_tuple, factor)\n",
        "\n",
        "\n",
        "def _random_saturation(rgb_tuple, rng, max_delta):\n",
        "  h, s, v = rgb_to_hsv(*rgb_tuple)\n",
        "  factor = jax.random.uniform(\n",
        "      rng, shape=(), minval=1 - max_delta, maxval=1 + max_delta)\n",
        "  return hsv_to_rgb(*adjust_saturation(h, s, v, factor))\n",
        "\n",
        "\n",
        "def _random_hue(rgb_tuple, rng, max_delta):\n",
        "  h, s, v = rgb_to_hsv(*rgb_tuple)\n",
        "  delta = jax.random.uniform(rng, shape=(), minval=-max_delta, maxval=max_delta)\n",
        "  return hsv_to_rgb(*adjust_hue(h, s, v, delta))\n",
        "\n",
        "\n",
        "def _to_grayscale(image):\n",
        "  rgb_weights = jnp.array([0.2989, 0.5870, 0.1140])\n",
        "  grayscale = jnp.tensordot(image, rgb_weights, axes=(-1, -1))[..., jnp.newaxis]\n",
        "  return jnp.tile(grayscale, (1, 1, 3))  # Back to 3 channels.\n",
        "\n",
        "\n",
        "def _color_transform_single_image(image, rng, brightness, contrast, saturation,\n",
        "                                  hue, to_grayscale_prob, color_jitter_prob,\n",
        "                                  apply_prob, shuffle):\n",
        "  \"\"\"Applies color jittering to a single image.\"\"\"\n",
        "  apply_rng, transform_rng = jax.random.split(rng)\n",
        "  perm_rng, b_rng, c_rng, s_rng, h_rng, cj_rng, gs_rng = jax.random.split(\n",
        "      transform_rng, 7)\n",
        "\n",
        "  # Whether the transform should be applied at all.\n",
        "  should_apply = jax.random.uniform(apply_rng, shape=()) <= apply_prob\n",
        "  # Whether to apply grayscale transform.\n",
        "  should_apply_gs = jax.random.uniform(gs_rng, shape=()) <= to_grayscale_prob\n",
        "  # Whether to apply color jittering.\n",
        "  should_apply_color = jax.random.uniform(cj_rng, shape=()) <= color_jitter_prob\n",
        "\n",
        "  # Decorator to conditionally apply fn based on an index.\n",
        "  def _make_cond(fn, idx):\n",
        "\n",
        "    def identity_fn(x, unused_rng, unused_param):\n",
        "      return x\n",
        "\n",
        "    def cond_fn(args, i):\n",
        "      def clip(args):\n",
        "        return jax.tree_map(lambda arg: jnp.clip(arg, 0., 1.), args)\n",
        "      out = jax.lax.cond(should_apply & should_apply_color & (i == idx), args,\n",
        "                         lambda a: clip(fn(*a)), args,\n",
        "                         lambda a: identity_fn(*a))\n",
        "      return jax.lax.stop_gradient(out)\n",
        "\n",
        "    return cond_fn\n",
        "\n",
        "  random_brightness_cond = _make_cond(_random_brightness, idx=0)\n",
        "  random_contrast_cond = _make_cond(_random_contrast, idx=1)\n",
        "  random_saturation_cond = _make_cond(_random_saturation, idx=2)\n",
        "  random_hue_cond = _make_cond(_random_hue, idx=3)\n",
        "\n",
        "  def _color_jitter(x):\n",
        "    rgb_tuple = tuple(jax.tree_map(jnp.squeeze, jnp.split(x, 3, axis=-1)))\n",
        "    if shuffle:\n",
        "      order = jax.random.permutation(perm_rng, jnp.arange(4, dtype=jnp.int32))\n",
        "    else:\n",
        "      order = range(4)\n",
        "    for idx in order:\n",
        "      if brightness > 0:\n",
        "        rgb_tuple = random_brightness_cond((rgb_tuple, b_rng, brightness), idx)\n",
        "      if contrast > 0:\n",
        "        rgb_tuple = random_contrast_cond((rgb_tuple, c_rng, contrast), idx)\n",
        "      if saturation > 0:\n",
        "        rgb_tuple = random_saturation_cond((rgb_tuple, s_rng, saturation), idx)\n",
        "      if hue > 0:\n",
        "        rgb_tuple = random_hue_cond((rgb_tuple, h_rng, hue), idx)\n",
        "    return jnp.stack(rgb_tuple, axis=-1)\n",
        "\n",
        "  out_apply = _color_jitter(image)\n",
        "  out_apply = jax.lax.cond(should_apply & should_apply_gs, out_apply,\n",
        "                           _to_grayscale, out_apply, lambda x: x)\n",
        "  return jnp.clip(out_apply, 0., 1.)\n",
        "\n",
        "\n",
        "def _random_flip_single_image(image, rng):\n",
        "  _, flip_rng = jax.random.split(rng)\n",
        "  should_flip_lr = jax.random.uniform(flip_rng, shape=()) <= 0.5\n",
        "  image = jax.lax.cond(should_flip_lr, image, jnp.fliplr, image, lambda x: x)\n",
        "  return image\n",
        "\n",
        "\n",
        "def random_flip(images, rng):\n",
        "  rngs = jax.random.split(rng, images.shape[0])\n",
        "  return jax.vmap(_random_flip_single_image)(images, rngs)\n",
        "\n",
        "\n",
        "def color_transform(images,\n",
        "                    rng,\n",
        "                    brightness=0.8,\n",
        "                    contrast=0.8,\n",
        "                    saturation=0.8,\n",
        "                    hue=0.2,\n",
        "                    color_jitter_prob=0.8,\n",
        "                    to_grayscale_prob=0.2,\n",
        "                    apply_prob=1.0,\n",
        "                    shuffle=True):\n",
        "  \"\"\"Applies color jittering and/or grayscaling to a batch of images.\n",
        "\n",
        "  Args:\n",
        "    images: an NHWC tensor, with C=3.\n",
        "    rng: a single PRNGKey.\n",
        "    brightness: the range of jitter on brightness.\n",
        "    contrast: the range of jitter on contrast.\n",
        "    saturation: the range of jitter on saturation.\n",
        "    hue: the range of jitter on hue.\n",
        "    color_jitter_prob: the probability of applying color jittering.\n",
        "    to_grayscale_prob: the probability of converting the image to grayscale.\n",
        "    apply_prob: the probability of applying the transform to a batch element.\n",
        "    shuffle: whether to apply the transforms in a random order.\n",
        "\n",
        "  Returns:\n",
        "    A NHWC tensor of the transformed images.\n",
        "  \"\"\"\n",
        "  rngs = jax.random.split(rng, images.shape[0])\n",
        "  jitter_fn = functools.partial(\n",
        "      _color_transform_single_image,\n",
        "      brightness=brightness,\n",
        "      contrast=contrast,\n",
        "      saturation=saturation,\n",
        "      hue=hue,\n",
        "      color_jitter_prob=color_jitter_prob,\n",
        "      to_grayscale_prob=to_grayscale_prob,\n",
        "      apply_prob=apply_prob,\n",
        "      shuffle=shuffle)\n",
        "  return jax.vmap(jitter_fn)(images, rngs)\n",
        "\n",
        "\n",
        "def gaussian_blur(images,\n",
        "                  rng,\n",
        "                  blur_divider=10.,\n",
        "                  sigma_min=0.1,\n",
        "                  sigma_max=2.0,\n",
        "                  apply_prob=1.0):\n",
        "  \"\"\"Applies gaussian blur to a batch of images.\n",
        "\n",
        "  Args:\n",
        "    images: an NHWC tensor, with C=3.\n",
        "    rng: a single PRNGKey.\n",
        "    blur_divider: the blurring kernel will have size H / blur_divider.\n",
        "    sigma_min: the minimum value for sigma in the blurring kernel.\n",
        "    sigma_max: the maximum value for sigma in the blurring kernel.\n",
        "    apply_prob: the probability of applying the transform to a batch element.\n",
        "\n",
        "  Returns:\n",
        "    A NHWC tensor of the blurred images.\n",
        "  \"\"\"\n",
        "  rngs = jax.random.split(rng, images.shape[0])\n",
        "  kernel_size = images.shape[1] / blur_divider\n",
        "  blur_fn = functools.partial(\n",
        "      _random_gaussian_blur,\n",
        "      kernel_size=kernel_size,\n",
        "      padding='SAME',\n",
        "      sigma_min=sigma_min,\n",
        "      sigma_max=sigma_max,\n",
        "      apply_prob=apply_prob)\n",
        "  return jax.vmap(blur_fn)(images, rngs)\n",
        "\n",
        "\n",
        "def _solarize_single_image(image, rng, threshold, apply_prob):\n",
        "\n",
        "  def _apply(image):\n",
        "    return jnp.where(image < threshold, image, 1. - image)\n",
        "\n",
        "  return _maybe_apply(_apply, image, rng, apply_prob)\n",
        "\n",
        "\n",
        "def solarize(images, rng, threshold=0.5, apply_prob=1.0):\n",
        "  \"\"\"Applies solarization.\n",
        "\n",
        "  Args:\n",
        "    images: an NHWC tensor (with C=3).\n",
        "    rng: a single PRNGKey.\n",
        "    threshold: the solarization threshold.\n",
        "    apply_prob: the probability of applying the transform to a batch element.\n",
        "\n",
        "  Returns:\n",
        "    A NHWC tensor of the transformed images.\n",
        "  \"\"\"\n",
        "  rngs = jax.random.split(rng, images.shape[0])\n",
        "  solarize_fn = functools.partial(\n",
        "      _solarize_single_image, threshold=threshold, apply_prob=apply_prob)\n",
        "  return jax.vmap(solarize_fn)(images, rngs)\n"
      ],
      "metadata": {
        "id": "muHShxFk83_s"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Checkpoint saving and restoring utilities.\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "from typing import Mapping, Text, Tuple, Union\n",
        "\n",
        "from absl import logging\n",
        "import dill\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "#from byol.utils import helpers\n",
        "\n",
        "\n",
        "class Checkpointer:\n",
        "  \"\"\"A checkpoint saving and loading class.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      use_checkpointing: bool,\n",
        "      checkpoint_dir: Text,\n",
        "      save_checkpoint_interval: int,\n",
        "      filename: Text):\n",
        "    if (not use_checkpointing or\n",
        "        checkpoint_dir is None or\n",
        "        save_checkpoint_interval <= 0):\n",
        "      self._checkpoint_enabled = False\n",
        "      return\n",
        "\n",
        "    self._checkpoint_enabled = True\n",
        "    self._checkpoint_dir = checkpoint_dir\n",
        "    os.makedirs(self._checkpoint_dir, exist_ok=True)\n",
        "    self._filename = filename\n",
        "    self._checkpoint_path = os.path.join(self._checkpoint_dir, filename)\n",
        "    self._last_checkpoint_time = 0\n",
        "    self._checkpoint_every = save_checkpoint_interval\n",
        "\n",
        "  def maybe_save_checkpoint(\n",
        "      self,\n",
        "      experiment_state: Mapping[Text, jnp.ndarray],\n",
        "      step: int,\n",
        "      rng: jnp.ndarray,\n",
        "      is_final: bool):\n",
        "    \"\"\"Saves a checkpoint if enough time has passed since the previous one.\"\"\"\n",
        "    current_time = time.time()\n",
        "    if (not self._checkpoint_enabled or\n",
        "        jax.host_id() != 0 or  # Only checkpoint the first worker.\n",
        "        (not is_final and\n",
        "         current_time - self._last_checkpoint_time < self._checkpoint_every)):\n",
        "      return\n",
        "    checkpoint_data = dict(\n",
        "        experiment_state=jax.tree_map(\n",
        "            lambda x: jax.device_get(x[0]), experiment_state),\n",
        "        step=step,\n",
        "        rng=rng)\n",
        "    with open(self._checkpoint_path + '_tmp', 'wb') as checkpoint_file:\n",
        "      dill.dump(checkpoint_data, checkpoint_file, protocol=2)\n",
        "    try:\n",
        "      os.rename(self._checkpoint_path, self._checkpoint_path + '_old')\n",
        "      remove_old = True\n",
        "    except FileNotFoundError:\n",
        "      remove_old = False  # No previous checkpoint to remove\n",
        "    os.rename(self._checkpoint_path + '_tmp', self._checkpoint_path)\n",
        "    if remove_old:\n",
        "      os.remove(self._checkpoint_path + '_old')\n",
        "    self._last_checkpoint_time = current_time\n",
        "\n",
        "  def maybe_load_checkpoint(\n",
        "      self) -> Union[Tuple[Mapping[Text, jnp.ndarray], int, jnp.ndarray], None]:\n",
        "    \"\"\"Loads a checkpoint if any is found.\"\"\"\n",
        "    checkpoint_data = load_checkpoint(self._checkpoint_path)\n",
        "    if checkpoint_data is None:\n",
        "      logging.info('No existing checkpoint found at %s', self._checkpoint_path)\n",
        "      return None\n",
        "    step = checkpoint_data['step']\n",
        "    rng = checkpoint_data['rng']\n",
        "    experiment_state = jax.tree_map(\n",
        "        helpers.bcast_local_devices, checkpoint_data['experiment_state'])\n",
        "    del checkpoint_data\n",
        "    return experiment_state, step, rng\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_path):\n",
        "  try:\n",
        "    with open(checkpoint_path, 'rb') as checkpoint_file:\n",
        "      checkpoint_data = dill.load(checkpoint_file)\n",
        "      logging.info('Loading checkpoint from %s, saved at step %d',\n",
        "                   checkpoint_path, checkpoint_data['step'])\n",
        "      return checkpoint_data\n",
        "  except FileNotFoundError:\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "Sb2gmLwf9gTP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"ImageNet dataset with typical pre-processing.\"\"\"\n",
        "\n",
        "import enum\n",
        "from typing import Generator, Mapping, Optional, Sequence, Text, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "Batch = Mapping[Text, np.ndarray]\n",
        "\n",
        "\n",
        "class Split(enum.Enum):\n",
        "  \"\"\"Imagenet dataset split.\"\"\"\n",
        "  TRAIN = 1\n",
        "  TRAIN_AND_VALID = 2\n",
        "  VALID = 3\n",
        "  TEST = 4\n",
        "\n",
        "  @classmethod\n",
        "  def from_string(cls, name: Text) -> 'Split':\n",
        "    return {\n",
        "        'TRAIN': Split.TRAIN,\n",
        "        'TRAIN_AND_VALID': Split.TRAIN_AND_VALID,\n",
        "        'VALID': Split.VALID,\n",
        "        'VALIDATION': Split.VALID,\n",
        "        'TEST': Split.TEST\n",
        "    }[name.upper()]\n",
        "\n",
        "  @property\n",
        "  def num_examples(self):\n",
        "    return {\n",
        "        Split.TRAIN_AND_VALID: 60000,\n",
        "        Split.TRAIN: 50000,\n",
        "        Split.VALID: 0,\n",
        "        Split.TEST: 10000\n",
        "    }[self]\n",
        "\n",
        "\n",
        "class PreprocessMode(enum.Enum):\n",
        "  \"\"\"Preprocessing modes for the dataset.\"\"\"\n",
        "  PRETRAIN = 1  # Generates two augmented views (random crop + augmentations).\n",
        "  LINEAR_TRAIN = 2  # Generates a single random crop.\n",
        "  EVAL = 3  # Generates a single center crop.\n",
        "\n",
        "\n",
        "def normalize_images(images: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Normalize the image using ImageNet statistics.\"\"\"\n",
        "  mean_rgb = (0.485, 0.456, 0.406)\n",
        "  stddev_rgb = (0.229, 0.224, 0.225)\n",
        "  normed_images = images - jnp.array(mean_rgb).reshape((1, 1, 1, 3))\n",
        "  normed_images = normed_images / jnp.array(stddev_rgb).reshape((1, 1, 1, 3))\n",
        "  return normed_images\n",
        "\n",
        "\n",
        "def load(split: Split,\n",
        "         *,\n",
        "         preprocess_mode: PreprocessMode,\n",
        "         batch_dims: Sequence[int],\n",
        "         transpose: bool = False,\n",
        "         allow_caching: bool = False) -> Generator[Batch, None, None]:\n",
        "  \"\"\"Loads the given split of the dataset.\"\"\"\n",
        "  start, end = _shard(split, jax.host_id(), jax.host_count())\n",
        "\n",
        "  total_batch_size = np.prod(batch_dims)\n",
        "\n",
        "  tfds_split = tfds.core.ReadInstruction(\n",
        "      _to_tfds_split(split), from_=start, to=end, unit='abs')\n",
        "  ds = tfds.load(\n",
        "      #'imagenet2012:5.*.*',\n",
        "      'cifar100',\n",
        "      split=tfds_split,\n",
        "      decoders={'image': tfds.decode.SkipDecoding()})\n",
        "\n",
        "  options = tf.data.Options()\n",
        "  options.experimental_threading.private_threadpool_size = 48\n",
        "  options.experimental_threading.max_intra_op_parallelism = 1\n",
        "\n",
        "  if preprocess_mode is not PreprocessMode.EVAL:\n",
        "    options.experimental_deterministic = False\n",
        "    if jax.host_count() > 1 and allow_caching:\n",
        "      # Only cache if we are reading a subset of the dataset.\n",
        "      ds = ds.cache()\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.shuffle(buffer_size=10 * total_batch_size, seed=0)\n",
        "\n",
        "  else:\n",
        "    if split.num_examples % total_batch_size != 0:\n",
        "      raise ValueError(f'Test/valid must be divisible by {total_batch_size}')\n",
        "\n",
        "  ds = ds.with_options(options)\n",
        "\n",
        "  def preprocess_pretrain(example):\n",
        "    view1 = _preprocess_image(example['image'], mode=preprocess_mode)\n",
        "    view2 = _preprocess_image(example['image'], mode=preprocess_mode)\n",
        "    label = tf.cast(example['label'], tf.int32)\n",
        "    return {'view1': view1, 'view2': view2, 'labels': label}\n",
        "\n",
        "  def preprocess_linear_train(example):\n",
        "    image = _preprocess_image(example['image'], mode=preprocess_mode)\n",
        "    label = tf.cast(example['label'], tf.int32)\n",
        "    return {'images': image, 'labels': label}\n",
        "\n",
        "  def preprocess_eval(example):\n",
        "    image = _preprocess_image(example['image'], mode=preprocess_mode)\n",
        "    label = tf.cast(example['label'], tf.int32)\n",
        "    return {'images': image, 'labels': label}\n",
        "\n",
        "  if preprocess_mode is PreprocessMode.PRETRAIN:\n",
        "    ds = ds.map(\n",
        "        preprocess_pretrain, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  elif preprocess_mode is PreprocessMode.LINEAR_TRAIN:\n",
        "    ds = ds.map(\n",
        "        preprocess_linear_train,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  else:\n",
        "    ds = ds.map(\n",
        "        preprocess_eval, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  def transpose_fn(batch):\n",
        "    # We use the double-transpose-trick to improve performance for TPUs. Note\n",
        "    # that this (typically) requires a matching HWCN->NHWC transpose in your\n",
        "    # model code. The compiler cannot make this optimization for us since our\n",
        "    # data pipeline and model are compiled separately.\n",
        "    batch = dict(**batch)\n",
        "    if preprocess_mode is PreprocessMode.PRETRAIN:\n",
        "      batch['view1'] = tf.transpose(batch['view1'], (1, 2, 3, 0))\n",
        "      batch['view2'] = tf.transpose(batch['view2'], (1, 2, 3, 0))\n",
        "    else:\n",
        "      batch['images'] = tf.transpose(batch['images'], (1, 2, 3, 0))\n",
        "    return batch\n",
        "\n",
        "  for i, batch_size in enumerate(reversed(batch_dims)):\n",
        "    ds = ds.batch(batch_size)\n",
        "    if i == 0 and transpose:\n",
        "      ds = ds.map(transpose_fn)  # NHWC -> HWCN\n",
        "\n",
        "  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  yield from tfds.as_numpy(ds)\n",
        "\n",
        "\n",
        "def _to_tfds_split(split: Split) -> tfds.Split:\n",
        "  \"\"\"Returns the TFDS split appropriately sharded.\"\"\"\n",
        "  # NOTE: Imagenet did not release labels for the test split used in the\n",
        "  # competition, we consider the VALID split the TEST split and reserve\n",
        "  # 10k images from TRAIN for VALID.\n",
        "  if split in (Split.TRAIN, Split.TRAIN_AND_VALID, Split.VALID):\n",
        "    return tfds.Split.TRAIN\n",
        "  else:\n",
        "    assert split == Split.TEST\n",
        "    return tfds.Split.VALIDATION\n",
        "\n",
        "\n",
        "def _shard(split: Split, shard_index: int, num_shards: int) -> Tuple[int, int]:\n",
        "  \"\"\"Returns [start, end) for the given shard index.\"\"\"\n",
        "  assert shard_index < num_shards\n",
        "  arange = np.arange(split.num_examples)\n",
        "  shard_range = np.array_split(arange, num_shards)[shard_index]\n",
        "  start, end = shard_range[0], (shard_range[-1] + 1)\n",
        "  if split == Split.TRAIN:\n",
        "    # Note that our TRAIN=TFDS_TRAIN[10000:] and VALID=TFDS_TRAIN[:10000].\n",
        "    offset = Split.VALID.num_examples\n",
        "    start += offset\n",
        "    end += offset\n",
        "  return start, end\n",
        "\n",
        "\n",
        "def _preprocess_image(\n",
        "    image_bytes: tf.Tensor,\n",
        "    mode: PreprocessMode,\n",
        ") -> tf.Tensor:\n",
        "  \"\"\"Returns processed and resized images.\"\"\"\n",
        "  if mode is PreprocessMode.PRETRAIN:\n",
        "    image = _decode_and_random_crop(image_bytes)\n",
        "    # Random horizontal flipping is optionally done in augmentations.preprocess.\n",
        "  elif mode is PreprocessMode.LINEAR_TRAIN:\n",
        "    image = _decode_and_random_crop(image_bytes)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "  else:\n",
        "    image = _decode_and_center_crop(image_bytes)\n",
        "  # NOTE: Bicubic resize (1) casts uint8 to float32 and (2) resizes without\n",
        "  # clamping overshoots. This means values returned will be outside the range\n",
        "  # [0.0, 255.0] (e.g. we have observed outputs in the range [-51.1, 336.6]).\n",
        "  assert image.dtype == tf.uint8\n",
        "  image = tf.image.resize(image, [224, 224], tf.image.ResizeMethod.BICUBIC)\n",
        "  image = tf.clip_by_value(image / 255., 0., 1.)\n",
        "  return image\n",
        "\n",
        "\n",
        "def _decode_and_random_crop(image_bytes: tf.Tensor) -> tf.Tensor:\n",
        "  \"\"\"Make a random crop of 224.\"\"\"\n",
        "  img_size = tf.image.extract_jpeg_shape(image_bytes)\n",
        "  area = tf.cast(img_size[1] * img_size[0], tf.float32)\n",
        "  target_area = tf.random.uniform([], 0.08, 1.0, dtype=tf.float32) * area\n",
        "\n",
        "  log_ratio = (tf.math.log(3 / 4), tf.math.log(4 / 3))\n",
        "  aspect_ratio = tf.math.exp(\n",
        "      tf.random.uniform([], *log_ratio, dtype=tf.float32))\n",
        "\n",
        "  w = tf.cast(tf.round(tf.sqrt(target_area * aspect_ratio)), tf.int32)\n",
        "  h = tf.cast(tf.round(tf.sqrt(target_area / aspect_ratio)), tf.int32)\n",
        "\n",
        "  w = tf.minimum(w, img_size[1])\n",
        "  h = tf.minimum(h, img_size[0])\n",
        "\n",
        "  offset_w = tf.random.uniform((),\n",
        "                               minval=0,\n",
        "                               maxval=img_size[1] - w + 1,\n",
        "                               dtype=tf.int32)\n",
        "  offset_h = tf.random.uniform((),\n",
        "                               minval=0,\n",
        "                               maxval=img_size[0] - h + 1,\n",
        "                               dtype=tf.int32)\n",
        "\n",
        "  crop_window = tf.stack([offset_h, offset_w, h, w])\n",
        "  image = tf.io.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n",
        "  return image\n",
        "\n",
        "\n",
        "def transpose_images(batch: Batch):\n",
        "  \"\"\"Transpose images for TPU training..\"\"\"\n",
        "  new_batch = dict(batch)  # Avoid mutating in place.\n",
        "  if 'images' in batch:\n",
        "    new_batch['images'] = jnp.transpose(batch['images'], (3, 0, 1, 2))\n",
        "  else:\n",
        "    new_batch['view1'] = jnp.transpose(batch['view1'], (3, 0, 1, 2))\n",
        "    new_batch['view2'] = jnp.transpose(batch['view2'], (3, 0, 1, 2))\n",
        "  return new_batch\n",
        "\n",
        "\n",
        "def _decode_and_center_crop(\n",
        "    image_bytes: tf.Tensor,\n",
        "    jpeg_shape: Optional[tf.Tensor] = None,\n",
        ") -> tf.Tensor:\n",
        "  \"\"\"Crops to center of image with padding then scales.\"\"\"\n",
        "  if jpeg_shape is None:\n",
        "    jpeg_shape = tf.image.extract_jpeg_shape(image_bytes)\n",
        "  image_height = jpeg_shape[0]\n",
        "  image_width = jpeg_shape[1]\n",
        "\n",
        "  padded_center_crop_size = tf.cast(\n",
        "      ((224 / (224 + 32)) *\n",
        "       tf.cast(tf.minimum(image_height, image_width), tf.float32)), tf.int32)\n",
        "\n",
        "  offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n",
        "  offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n",
        "  crop_window = tf.stack([\n",
        "      offset_height, offset_width, padded_center_crop_size,\n",
        "      padded_center_crop_size\n",
        "  ])\n",
        "  image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n",
        "  return image\n"
      ],
      "metadata": {
        "id": "4WkUXxJd99aP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Networks used in BYOL.\"\"\"\n",
        "\n",
        "from typing import Any, Mapping, Optional, Sequence, Text\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "class MLP(hk.Module):\n",
        "  \"\"\"One hidden layer perceptron, with normalization.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      name: Text,\n",
        "      hidden_size: int,\n",
        "      output_size: int,\n",
        "      bn_config: Mapping[Text, Any],\n",
        "  ):\n",
        "    super().__init__(name=name)\n",
        "    self._hidden_size = hidden_size\n",
        "    self._output_size = output_size\n",
        "    self._bn_config = bn_config\n",
        "\n",
        "  def __call__(self, inputs: jnp.ndarray, is_training: bool) -> jnp.ndarray:\n",
        "    out = hk.Linear(output_size=self._hidden_size, with_bias=True)(inputs)\n",
        "    out = hk.BatchNorm(**self._bn_config)(out, is_training=is_training)\n",
        "    out = jax.nn.relu(out)\n",
        "    out = hk.Linear(output_size=self._output_size, with_bias=False)(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "def check_length(length, value, name):\n",
        "  if len(value) != length:\n",
        "    raise ValueError(f'`{name}` must be of length 4 not {len(value)}')\n",
        "\n",
        "\n",
        "class ResNetTorso(hk.Module):\n",
        "  \"\"\"ResNet model.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      blocks_per_group: Sequence[int],\n",
        "      num_classes: Optional[int] = None,\n",
        "      bn_config: Optional[Mapping[str, float]] = None,\n",
        "      resnet_v2: bool = False,\n",
        "      bottleneck: bool = True,\n",
        "      channels_per_group: Sequence[int] = (256, 512, 1024, 2048),\n",
        "      use_projection: Sequence[bool] = (True, True, True, True),\n",
        "      width_multiplier: int = 1,\n",
        "      name: Optional[str] = None,\n",
        "  ):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "\n",
        "    Args:\n",
        "      blocks_per_group: A sequence of length 4 that indicates the number of\n",
        "        blocks created in each group.\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of three elements, `decay_rate`, `eps`, and\n",
        "        `cross_replica_axis`, to be passed on to the `BatchNorm` layers. By\n",
        "        default the `decay_rate` is `0.9` and `eps` is `1e-5`, and the axis is\n",
        "        `None`.\n",
        "      resnet_v2: Whether to use the v1 or v2 ResNet implementation. Defaults to\n",
        "        False.\n",
        "       bottleneck: Whether the block should bottleneck or not. Defaults to True.\n",
        "      channels_per_group: A sequence of length 4 that indicates the number\n",
        "        of channels used for each block in each group.\n",
        "      use_projection: A sequence of length 4 that indicates whether each\n",
        "        residual block should use projection.\n",
        "      width_multiplier: An integer multiplying the number of channels per group.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(name=name)\n",
        "    self.resnet_v2 = resnet_v2\n",
        "\n",
        "    bn_config = dict(bn_config or {})\n",
        "    bn_config.setdefault('decay_rate', 0.9)\n",
        "    bn_config.setdefault('eps', 1e-5)\n",
        "    bn_config.setdefault('create_scale', True)\n",
        "    bn_config.setdefault('create_offset', True)\n",
        "\n",
        "    # Number of blocks in each group for ResNet.\n",
        "    check_length(4, blocks_per_group, 'blocks_per_group')\n",
        "    check_length(4, channels_per_group, 'channels_per_group')\n",
        "\n",
        "    self.initial_conv = hk.Conv2D(\n",
        "        output_channels=64 * width_multiplier,\n",
        "        kernel_shape=7,\n",
        "        stride=2,\n",
        "        with_bias=False,\n",
        "        padding='SAME',\n",
        "        name='initial_conv')\n",
        "\n",
        "    if not self.resnet_v2:\n",
        "      self.initial_batchnorm = hk.BatchNorm(name='initial_batchnorm',\n",
        "                                            **bn_config)\n",
        "\n",
        "    self.block_groups = []\n",
        "    strides = (1, 2, 2, 2)\n",
        "    for i in range(4):\n",
        "      self.block_groups.append(\n",
        "          hk.nets.ResNet.BlockGroup(\n",
        "              channels=width_multiplier * channels_per_group[i],\n",
        "              num_blocks=blocks_per_group[i],\n",
        "              stride=strides[i],\n",
        "              bn_config=bn_config,\n",
        "              resnet_v2=resnet_v2,\n",
        "              bottleneck=bottleneck,\n",
        "              use_projection=use_projection[i],\n",
        "              name='block_group_%d' % (i)))\n",
        "\n",
        "    if self.resnet_v2:\n",
        "      self.final_batchnorm = hk.BatchNorm(name='final_batchnorm', **bn_config)\n",
        "\n",
        "    self.logits = hk.Linear(num_classes, w_init=jnp.zeros, name='logits')\n",
        "\n",
        "  def __call__(self, inputs, is_training, test_local_stats=False):\n",
        "    out = inputs\n",
        "    out = self.initial_conv(out)\n",
        "    if not self.resnet_v2:\n",
        "      out = self.initial_batchnorm(out, is_training, test_local_stats)\n",
        "      out = jax.nn.relu(out)\n",
        "\n",
        "    out = hk.max_pool(out,\n",
        "                      window_shape=(1, 3, 3, 1),\n",
        "                      strides=(1, 2, 2, 1),\n",
        "                      padding='SAME')\n",
        "\n",
        "    for block_group in self.block_groups:\n",
        "      out = block_group(out, is_training, test_local_stats)\n",
        "\n",
        "    if self.resnet_v2:\n",
        "      out = self.final_batchnorm(out, is_training, test_local_stats)\n",
        "      out = jax.nn.relu(out)\n",
        "    out = jnp.mean(out, axis=[1, 2])\n",
        "    return out\n",
        "\n",
        "\n",
        "class TinyResNet(ResNetTorso):\n",
        "  \"\"\"Tiny resnet for local runs and tests.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes: Optional[int] = None,\n",
        "               bn_config: Optional[Mapping[str, float]] = None,\n",
        "               resnet_v2: bool = False,\n",
        "               width_multiplier: int = 1,\n",
        "               name: Optional[str] = None):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "\n",
        "    Args:\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers.\n",
        "      resnet_v2: Whether to use the v1 or v2 ResNet implementation. Defaults\n",
        "        to False.\n",
        "      width_multiplier: An integer multiplying the number of channels per group.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(blocks_per_group=(1, 1, 1, 1),\n",
        "                     channels_per_group=(8, 8, 8, 8),\n",
        "                     num_classes=num_classes,\n",
        "                     bn_config=bn_config,\n",
        "                     resnet_v2=resnet_v2,\n",
        "                     bottleneck=False,\n",
        "                     width_multiplier=width_multiplier,\n",
        "                     name=name)\n",
        "\n",
        "\n",
        "class ResNet18(ResNetTorso):\n",
        "  \"\"\"ResNet18.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes: Optional[int] = None,\n",
        "               bn_config: Optional[Mapping[str, float]] = None,\n",
        "               resnet_v2: bool = False,\n",
        "               width_multiplier: int = 1,\n",
        "               name: Optional[str] = None):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "\n",
        "    Args:\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers.\n",
        "      resnet_v2: Whether to use the v1 or v2 ResNet implementation. Defaults\n",
        "        to False.\n",
        "      width_multiplier: An integer multiplying the number of channels per group.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(blocks_per_group=(2, 2, 2, 2),\n",
        "                     num_classes=num_classes,\n",
        "                     bn_config=bn_config,\n",
        "                     resnet_v2=resnet_v2,\n",
        "                     bottleneck=False,\n",
        "                     channels_per_group=(64, 128, 256, 512),\n",
        "                     width_multiplier=width_multiplier,\n",
        "                     name=name)\n",
        "\n",
        "\n",
        "class ResNet34(ResNetTorso):\n",
        "  \"\"\"ResNet34.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes: Optional[int],\n",
        "               bn_config: Optional[Mapping[str, float]] = None,\n",
        "               resnet_v2: bool = False,\n",
        "               width_multiplier: int = 1,\n",
        "               name: Optional[str] = None):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "\n",
        "    Args:\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers.\n",
        "      resnet_v2: Whether to use the v1 or v2 ResNet implementation. Defaults\n",
        "        to False.\n",
        "      width_multiplier: An integer multiplying the number of channels per group.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(blocks_per_group=(3, 4, 6, 3),\n",
        "                     num_classes=num_classes,\n",
        "                     bn_config=bn_config,\n",
        "                     resnet_v2=resnet_v2,\n",
        "                     bottleneck=False,\n",
        "                     channels_per_group=(64, 128, 256, 512),\n",
        "                     width_multiplier=width_multiplier,\n",
        "                     name=name)\n",
        "\n",
        "\n",
        "class ResNet50(ResNetTorso):\n",
        "  \"\"\"ResNet50.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes: Optional[int] = None,\n",
        "               bn_config: Optional[Mapping[str, float]] = None,\n",
        "               resnet_v2: bool = False,\n",
        "               width_multiplier: int = 1,\n",
        "               name: Optional[str] = None):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "\n",
        "    Args:\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers.\n",
        "      resnet_v2: Whether to use the v1 or v2 ResNet implementation. Defaults\n",
        "        to False.\n",
        "      width_multiplier: An integer multiplying the number of channels per group.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(blocks_per_group=(3, 4, 6, 3),\n",
        "                     num_classes=num_classes,\n",
        "                     bn_config=bn_config,\n",
        "                     resnet_v2=resnet_v2,\n",
        "                     bottleneck=True,\n",
        "                     width_multiplier=width_multiplier,\n",
        "                     name=name)\n",
        "\n",
        "\n",
        "class ResNet101(ResNetTorso):\n",
        "  \"\"\"ResNet101.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes: Optional[int],\n",
        "               bn_config: Optional[Mapping[str, float]] = None,\n",
        "               resnet_v2: bool = False,\n",
        "               width_multiplier: int = 1,\n",
        "               name: Optional[str] = None):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "\n",
        "    Args:\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers.\n",
        "      resnet_v2: Whether to use the v1 or v2 ResNet implementation. Defaults\n",
        "        to False.\n",
        "      width_multiplier: An integer multiplying the number of channels per group.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(blocks_per_group=(3, 4, 23, 3),\n",
        "                     num_classes=num_classes,\n",
        "                     bn_config=bn_config,\n",
        "                     resnet_v2=resnet_v2,\n",
        "                     bottleneck=True,\n",
        "                     width_multiplier=width_multiplier,\n",
        "                     name=name)\n",
        "\n",
        "\n",
        "class ResNet152(ResNetTorso):\n",
        "  \"\"\"ResNet152.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes: Optional[int],\n",
        "               bn_config: Optional[Mapping[str, float]] = None,\n",
        "               resnet_v2: bool = False,\n",
        "               width_multiplier: int = 1,\n",
        "               name: Optional[str] = None):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "\n",
        "    Args:\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers.\n",
        "      resnet_v2: Whether to use the v1 or v2 ResNet implementation. Defaults\n",
        "        to False.\n",
        "      width_multiplier: An integer multiplying the number of channels per group.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(blocks_per_group=(3, 8, 36, 3),\n",
        "                     num_classes=num_classes,\n",
        "                     bn_config=bn_config,\n",
        "                     resnet_v2=resnet_v2,\n",
        "                     bottleneck=True,\n",
        "                     width_multiplier=width_multiplier,\n",
        "                     name=name)\n",
        "\n",
        "\n",
        "class ResNet200(ResNetTorso):\n",
        "  \"\"\"ResNet200.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes: Optional[int],\n",
        "               bn_config: Optional[Mapping[str, float]] = None,\n",
        "               resnet_v2: bool = False,\n",
        "               width_multiplier: int = 1,\n",
        "               name: Optional[str] = None):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "\n",
        "    Args:\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers.\n",
        "      resnet_v2: Whether to use the v1 or v2 ResNet implementation. Defaults\n",
        "        to False.\n",
        "      width_multiplier: An integer multiplying the number of channels per group.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(blocks_per_group=(3, 24, 36, 3),\n",
        "                     num_classes=num_classes,\n",
        "                     bn_config=bn_config,\n",
        "                     resnet_v2=resnet_v2,\n",
        "                     bottleneck=True,\n",
        "                     width_multiplier=width_multiplier,\n",
        "                     name=name)\n"
      ],
      "metadata": {
        "id": "qe4h7DQZ-Mzh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Implementation of LARS Optimizer with optax.\"\"\"\n",
        "\n",
        "from typing import Any, Callable, List, NamedTuple, Optional, Tuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import tree as nest\n",
        "\n",
        "# A filter function takes a path and a value as input and outputs True for\n",
        "# variable to apply update and False not to apply the update\n",
        "FilterFn = Callable[[Tuple[Any], jnp.ndarray], jnp.ndarray]\n",
        "\n",
        "\n",
        "def exclude_bias_and_norm(path: Tuple[Any], val: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Filter to exclude biaises and normalizations weights.\"\"\"\n",
        "  del val\n",
        "  if path[-1] == \"b\" or \"norm\" in path[-2]:\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "\n",
        "def _partial_update(updates: optax.Updates,\n",
        "                    new_updates: optax.Updates,\n",
        "                    params: optax.Params,\n",
        "                    filter_fn: Optional[FilterFn] = None) -> optax.Updates:\n",
        "  \"\"\"Returns new_update for params which filter_fn is True else updates.\"\"\"\n",
        "\n",
        "  if filter_fn is None:\n",
        "    return new_updates\n",
        "\n",
        "  wrapped_filter_fn = lambda x, y: jnp.array(filter_fn(x, y))\n",
        "  params_to_filter = nest.map_structure_with_path(wrapped_filter_fn, params)\n",
        "\n",
        "  def _update_fn(g: jnp.ndarray, t: jnp.ndarray, m: jnp.ndarray) -> jnp.ndarray:\n",
        "    m = m.astype(g.dtype)\n",
        "    return g * (1. - m) + t * m\n",
        "\n",
        "  return jax.tree_multimap(_update_fn, updates, new_updates, params_to_filter)\n",
        "\n",
        "\n",
        "class ScaleByLarsState(NamedTuple):\n",
        "  mu: jnp.ndarray\n",
        "\n",
        "\n",
        "def scale_by_lars(\n",
        "    momentum: float = 0.9,\n",
        "    eta: float = 0.001,\n",
        "    filter_fn: Optional[FilterFn] = None) -> optax.GradientTransformation:\n",
        "  \"\"\"Rescales updates according to the LARS algorithm.\n",
        "\n",
        "  Does not include weight decay.\n",
        "  References:\n",
        "    [You et al, 2017](https://arxiv.org/abs/1708.03888)\n",
        "\n",
        "  Args:\n",
        "    momentum: momentum coeficient.\n",
        "    eta: LARS coefficient.\n",
        "    filter_fn: an optional filter function.\n",
        "\n",
        "  Returns:\n",
        "    An (init_fn, update_fn) tuple.\n",
        "  \"\"\"\n",
        "\n",
        "  def init_fn(params: optax.Params) -> ScaleByLarsState:\n",
        "    mu = jax.tree_multimap(jnp.zeros_like, params)  # momentum\n",
        "    return ScaleByLarsState(mu=mu)\n",
        "\n",
        "  def update_fn(updates: optax.Updates, state: ScaleByLarsState,\n",
        "                params: optax.Params) -> Tuple[optax.Updates, ScaleByLarsState]:\n",
        "\n",
        "    def lars_adaptation(\n",
        "        update: jnp.ndarray,\n",
        "        param: jnp.ndarray,\n",
        "    ) -> jnp.ndarray:\n",
        "      param_norm = jnp.linalg.norm(param)\n",
        "      update_norm = jnp.linalg.norm(update)\n",
        "      return update * jnp.where(\n",
        "          param_norm > 0.,\n",
        "          jnp.where(update_norm > 0,\n",
        "                    (eta * param_norm / update_norm), 1.0), 1.0)\n",
        "\n",
        "    adapted_updates = jax.tree_multimap(lars_adaptation, updates, params)\n",
        "    adapted_updates = _partial_update(updates, adapted_updates, params,\n",
        "                                      filter_fn)\n",
        "    mu = jax.tree_multimap(lambda g, t: momentum * g + t,\n",
        "                           state.mu, adapted_updates)\n",
        "    return mu, ScaleByLarsState(mu=mu)\n",
        "\n",
        "  return optax.GradientTransformation(init_fn, update_fn)\n",
        "\n",
        "\n",
        "class AddWeightDecayState(NamedTuple):\n",
        "  \"\"\"Stateless transformation.\"\"\"\n",
        "\n",
        "\n",
        "def add_weight_decay(\n",
        "    weight_decay: float,\n",
        "    filter_fn: Optional[FilterFn] = None) -> optax.GradientTransformation:\n",
        "  \"\"\"Adds a weight decay to the update.\n",
        "\n",
        "  Args:\n",
        "    weight_decay: weight_decay coeficient.\n",
        "    filter_fn: an optional filter function.\n",
        "\n",
        "  Returns:\n",
        "    An (init_fn, update_fn) tuple.\n",
        "  \"\"\"\n",
        "\n",
        "  def init_fn(_) -> AddWeightDecayState:\n",
        "    return AddWeightDecayState()\n",
        "\n",
        "  def update_fn(\n",
        "      updates: optax.Updates,\n",
        "      state: AddWeightDecayState,\n",
        "      params: optax.Params,\n",
        "  ) -> Tuple[optax.Updates, AddWeightDecayState]:\n",
        "    new_updates = jax.tree_multimap(lambda g, p: g + weight_decay * p, updates,\n",
        "                                    params)\n",
        "    new_updates = _partial_update(updates, new_updates, params, filter_fn)\n",
        "    return new_updates, state\n",
        "\n",
        "  return optax.GradientTransformation(init_fn, update_fn)\n",
        "\n",
        "\n",
        "LarsState = List  # Type for the lars optimizer\n",
        "\n",
        "\n",
        "def lars(\n",
        "    learning_rate: float,\n",
        "    weight_decay: float = 0.,\n",
        "    momentum: float = 0.9,\n",
        "    eta: float = 0.001,\n",
        "    weight_decay_filter: Optional[FilterFn] = None,\n",
        "    lars_adaptation_filter: Optional[FilterFn] = None,\n",
        ") -> optax.GradientTransformation:\n",
        "  \"\"\"Creates lars optimizer with weight decay.\n",
        "\n",
        "  References:\n",
        "    [You et al, 2017](https://arxiv.org/abs/1708.03888)\n",
        "\n",
        "  Args:\n",
        "    learning_rate: learning rate coefficient.\n",
        "    weight_decay: weight decay coefficient.\n",
        "    momentum: momentum coefficient.\n",
        "    eta: LARS coefficient.\n",
        "    weight_decay_filter: optional filter function to only apply the weight\n",
        "      decay on a subset of parameters. The filter function takes as input the\n",
        "      parameter path (as a tuple) and its associated update, and return a True\n",
        "      for params to apply the weight decay and False for params to not apply\n",
        "      the weight decay. When weight_decay_filter is set to None, the weight\n",
        "      decay is not applied to the bias, i.e. when the variable name is 'b', and\n",
        "      the weight decay is not applied to nornalization params, i.e. the\n",
        "      panultimate path contains 'norm'.\n",
        "    lars_adaptation_filter: similar to weight decay filter but for lars\n",
        "      adaptation\n",
        "\n",
        "  Returns:\n",
        "    An optax.GradientTransformation, i.e. a (init_fn, update_fn) tuple.\n",
        "  \"\"\"\n",
        "\n",
        "  if weight_decay_filter is None:\n",
        "    weight_decay_filter = lambda *_: True\n",
        "  if lars_adaptation_filter is None:\n",
        "    lars_adaptation_filter = lambda *_: True\n",
        "\n",
        "  return optax.chain(\n",
        "      add_weight_decay(\n",
        "          weight_decay=weight_decay, filter_fn=weight_decay_filter),\n",
        "      scale_by_lars(\n",
        "          momentum=momentum, eta=eta, filter_fn=lars_adaptation_filter),\n",
        "      optax.scale(-learning_rate),\n",
        "  )\n"
      ],
      "metadata": {
        "id": "qtIPGaHo-SHO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Learning rate schedules.\"\"\"\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "def target_ema(global_step: jnp.ndarray,\n",
        "               base_ema: float,\n",
        "               max_steps: int) -> jnp.ndarray:\n",
        "  decay = _cosine_decay(global_step, max_steps, 1.)\n",
        "  return 1. - (1. - base_ema) * decay\n",
        "\n",
        "\n",
        "def learning_schedule(global_step: jnp.ndarray,\n",
        "                      batch_size: int,\n",
        "                      base_learning_rate: float,\n",
        "                      total_steps: int,\n",
        "                      warmup_steps: int) -> float:\n",
        "  \"\"\"Cosine learning rate scheduler.\"\"\"\n",
        "  # Compute LR & Scaled LR\n",
        "  scaled_lr = base_learning_rate * batch_size / 256.\n",
        "  learning_rate = (\n",
        "      global_step.astype(jnp.float32) / int(warmup_steps) *\n",
        "      scaled_lr if warmup_steps > 0 else scaled_lr)\n",
        "\n",
        "  # Cosine schedule after warmup.\n",
        "  return jnp.where(\n",
        "      global_step < warmup_steps, learning_rate,\n",
        "      _cosine_decay(global_step - warmup_steps, total_steps - warmup_steps,\n",
        "                    scaled_lr))\n",
        "\n",
        "\n",
        "def _cosine_decay(global_step: jnp.ndarray,\n",
        "                  max_steps: int,\n",
        "                  initial_value: float) -> jnp.ndarray:\n",
        "  \"\"\"Simple implementation of cosine decay from TF1.\"\"\"\n",
        "  global_step = jnp.minimum(global_step, max_steps)\n",
        "  cosine_decay_value = 0.5 * (1 + jnp.cos(jnp.pi * global_step / max_steps))\n",
        "  decayed_learning_rate = initial_value * cosine_decay_value\n",
        "  return decayed_learning_rate\n"
      ],
      "metadata": {
        "id": "c-amPuzr-aAe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from acme.jax import utils as acme_utils"
      ],
      "metadata": {
        "id": "VWUCUsKCsrGT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Utilities for JAX.\"\"\"\n",
        "\n",
        "import functools\n",
        "import itertools\n",
        "import queue\n",
        "import threading\n",
        "from typing import Callable, Generator, Iterable, NamedTuple, Optional, Sequence, Tuple, TypeVar\n",
        "\n",
        "from absl import logging\n",
        "from acme import types\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import tree\n",
        "\n",
        "F = TypeVar('F', bound=Callable)\n",
        "N = TypeVar('N', bound=types.NestedArray)\n",
        "T = TypeVar('T')\n",
        "\n",
        "def acme_utils_prefetch(iterable: Iterable[T],\n",
        "             buffer_size: int = 5,\n",
        "             device=None) -> Generator[T, None, None]:\n",
        "  \"\"\"Performs prefetching of elements from an iterable in a separate thread.\n",
        "  Args:\n",
        "    iterable: A python iterable. This is used to build the python prefetcher.\n",
        "      Note that each iterable should only be passed to this function once as\n",
        "      iterables aren't thread safe\n",
        "    buffer_size (int): Number of elements to keep in the prefetch buffer.\n",
        "    device: The device to prefetch the elements to. If none then the elements\n",
        "      are left on the CPU. The device should be of the type returned by\n",
        "      `jax.devices()`.\n",
        "  Yields:\n",
        "    Prefetched elements from the original iterable.\n",
        "  Raises:\n",
        "    ValueError if the buffer_size <= 1.\n",
        "    Any error thrown by the iterable_function. Note this is not raised inside\n",
        "      the producer, but after it finishes executing.\n",
        "  \"\"\"\n",
        "\n",
        "  if buffer_size <= 1:\n",
        "    raise ValueError('the buffer_size should be > 1')\n",
        "  buffer = queue.Queue(maxsize=(buffer_size - 1))\n",
        "  producer_error = []\n",
        "  end = object()\n",
        "\n",
        "  def producer():\n",
        "    \"\"\"Enqueues items from `iterable` on a given thread.\"\"\"\n",
        "    try:\n",
        "      # Build a new iterable for each thread. This is crucial if working with\n",
        "      # tensorflow datasets because tf.Graph objects are thread local.\n",
        "      for item in iterable:\n",
        "        if device:\n",
        "          item = jax.device_put(item, device)\n",
        "        buffer.put(item)\n",
        "    except Exception as e:  # pylint: disable=broad-except\n",
        "      logging.exception('Error in producer thread for %s', iterable)\n",
        "      producer_error.append(e)\n",
        "    finally:\n",
        "      buffer.put(end)\n",
        "\n",
        "  # Start the producer thread.\n",
        "  threading.Thread(target=producer, daemon=True).start()\n",
        "\n",
        "  # Consume from the buffer.\n",
        "  while True:\n",
        "    value = buffer.get()\n",
        "    if value is end:\n",
        "      break\n",
        "    yield value\n",
        "\n",
        "  if producer_error:\n",
        "    raise producer_error[0]"
      ],
      "metadata": {
        "id": "XbCZpqOup3FI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "4fGuNRNS80SG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "utPWcYY68cnN"
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"BYOL pre-training implementation.\n",
        "\n",
        "Use this experiment to pre-train a self-supervised representation.\n",
        "\"\"\"\n",
        "\n",
        "import functools\n",
        "from typing import Any, Generator, Mapping, NamedTuple, Text, Tuple, Union\n",
        "\n",
        "from absl import logging\n",
        "from acme.jax import utils as acme_utils\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "\n",
        "#from byol.utils import augmentations\n",
        "#from byol.utils import checkpointing\n",
        "#from byol.utils import dataset\n",
        "#from byol.utils import helpers\n",
        "#from byol.utils import networks\n",
        "#from byol.utils import optimizers\n",
        "#from byol.utils import schedules\n",
        "\n",
        "\n",
        "# Type declarations.\n",
        "LogsDict = Mapping[Text, jnp.ndarray]\n",
        "\n",
        "\n",
        "class _ByolExperimentState(NamedTuple):\n",
        "  \"\"\"Byol's model and optimization parameters and state.\"\"\"\n",
        "  online_params: hk.Params\n",
        "  target_params: hk.Params\n",
        "  online_state: hk.State\n",
        "  target_state: hk.State\n",
        "  opt_state: LarsState\n",
        "\n",
        "\n",
        "class ByolExperiment:\n",
        "  \"\"\"Byol's training and evaluation component definition.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      random_seed: int,\n",
        "      num_classes: int,\n",
        "      batch_size: int,\n",
        "      max_steps: int,\n",
        "      enable_double_transpose: bool,\n",
        "      base_target_ema: float,\n",
        "      network_config: Mapping[Text, Any],\n",
        "      optimizer_config: Mapping[Text, Any],\n",
        "      lr_schedule_config: Mapping[Text, Any],\n",
        "      evaluation_config: Mapping[Text, Any],\n",
        "      checkpointing_config: Mapping[Text, Any]):\n",
        "    \"\"\"Constructs the experiment.\n",
        "\n",
        "    Args:\n",
        "      random_seed: the random seed to use when initializing network weights.\n",
        "      num_classes: the number of classes; used for the online evaluation.\n",
        "      batch_size: the total batch size; should be a multiple of the number of\n",
        "        available accelerators.\n",
        "      max_steps: the number of training steps; used for the lr/target network\n",
        "        ema schedules.\n",
        "      enable_double_transpose: see dataset.py; only has effect on TPU.\n",
        "      base_target_ema: the initial value for the ema decay rate of the target\n",
        "        network.\n",
        "      network_config: the configuration for the network.\n",
        "      optimizer_config: the configuration for the optimizer.\n",
        "      lr_schedule_config: the configuration for the learning rate schedule.\n",
        "      evaluation_config: the evaluation configuration.\n",
        "      checkpointing_config: the configuration for checkpointing.\n",
        "    \"\"\"\n",
        "\n",
        "    self._random_seed = random_seed\n",
        "    self._enable_double_transpose = enable_double_transpose\n",
        "    self._num_classes = num_classes\n",
        "    self._lr_schedule_config = lr_schedule_config\n",
        "    self._batch_size = batch_size\n",
        "    self._max_steps = max_steps\n",
        "    self._base_target_ema = base_target_ema\n",
        "    self._optimizer_config = optimizer_config\n",
        "    self._evaluation_config = evaluation_config\n",
        "\n",
        "    # Checkpointed experiment state.\n",
        "    self._byol_state = None\n",
        "\n",
        "    # Input pipelines.\n",
        "    self._train_input = None\n",
        "    self._eval_input = None\n",
        "\n",
        "    # build the transformed ops\n",
        "    forward_fn = functools.partial(self._forward, **network_config)\n",
        "    self.forward = hk.without_apply_rng(hk.transform_with_state(forward_fn))\n",
        "    # training can handle multiple devices, thus the pmap\n",
        "    self.update_pmap = jax.pmap(self._update_fn, axis_name='i')\n",
        "    # evaluation can only handle single device\n",
        "    self.eval_batch_jit = jax.jit(self._eval_batch)\n",
        "\n",
        "    self._checkpointer = Checkpointer(**checkpointing_config)\n",
        "\n",
        "  def _forward(\n",
        "      self,\n",
        "      inputs: Batch,\n",
        "      projector_hidden_size: int,\n",
        "      projector_output_size: int,\n",
        "      predictor_hidden_size: int,\n",
        "      encoder_class: Text,\n",
        "      encoder_config: Mapping[Text, Any],\n",
        "      bn_config: Mapping[Text, Any],\n",
        "      is_training: bool,\n",
        "  ) -> Mapping[Text, jnp.ndarray]:\n",
        "    \"\"\"Forward application of byol's architecture.\n",
        "\n",
        "    Args:\n",
        "      inputs: A batch of data, i.e. a dictionary, with either two keys,\n",
        "        (`images` and `labels`) or three keys (`view1`, `view2`, `labels`).\n",
        "      projector_hidden_size: hidden size of the projector MLP.\n",
        "      projector_output_size: output size of the projector and predictor MLPs.\n",
        "      predictor_hidden_size: hidden size of the predictor MLP.\n",
        "      encoder_class: type of the encoder (should match a class in\n",
        "        utils/networks).\n",
        "      encoder_config: passed to the encoder constructor.\n",
        "      bn_config: passed to the hk.BatchNorm constructors.\n",
        "      is_training: Training or evaluating the model? When True, inputs must\n",
        "        contain keys `view1` and `view2`. When False, inputs must contain key\n",
        "        `images`.\n",
        "\n",
        "    Returns:\n",
        "      All outputs of the model, i.e. a dictionary with projection, prediction\n",
        "      and logits keys, for either the two views, or the image.\n",
        "    \"\"\"\n",
        "    encoder = getattr(networks, encoder_class)\n",
        "    net = encoder(\n",
        "        num_classes=None,  # Don't build the final linear layer\n",
        "        bn_config=bn_config,\n",
        "        **encoder_config)\n",
        "\n",
        "    projector = networks.MLP(\n",
        "        name='projector',\n",
        "        hidden_size=projector_hidden_size,\n",
        "        output_size=projector_output_size,\n",
        "        bn_config=bn_config)\n",
        "    predictor = networks.MLP(\n",
        "        name='predictor',\n",
        "        hidden_size=predictor_hidden_size,\n",
        "        output_size=projector_output_size,\n",
        "        bn_config=bn_config)\n",
        "    classifier = hk.Linear(\n",
        "        output_size=self._num_classes, name='classifier')\n",
        "\n",
        "    def apply_once_fn(images: jnp.ndarray, suffix: Text = ''):\n",
        "      images = normalize_images(images)\n",
        "\n",
        "      embedding = net(images, is_training=is_training)\n",
        "      proj_out = projector(embedding, is_training)\n",
        "      pred_out = predictor(proj_out, is_training)\n",
        "\n",
        "      # Note the stop_gradient: label information is not leaked into the\n",
        "      # main network.\n",
        "      classif_out = classifier(jax.lax.stop_gradient(embedding))\n",
        "      outputs = {}\n",
        "      outputs['projection' + suffix] = proj_out\n",
        "      outputs['prediction' + suffix] = pred_out\n",
        "      outputs['logits' + suffix] = classif_out\n",
        "      return outputs\n",
        "\n",
        "    if is_training:\n",
        "      outputs_view1 = apply_once_fn(inputs['view1'], '_view1')\n",
        "      outputs_view2 = apply_once_fn(inputs['view2'], '_view2')\n",
        "      return {**outputs_view1, **outputs_view2}\n",
        "    else:\n",
        "      return apply_once_fn(inputs['images'], '')\n",
        "\n",
        "  def _optimizer(self, learning_rate: float) -> optax.GradientTransformation:\n",
        "    \"\"\"Build optimizer from config.\"\"\"\n",
        "    return lars(\n",
        "        learning_rate,\n",
        "        weight_decay_filter=exclude_bias_and_norm,\n",
        "        lars_adaptation_filter=exclude_bias_and_norm,\n",
        "        **self._optimizer_config)\n",
        "\n",
        "  def loss_fn(\n",
        "      self,\n",
        "      online_params: hk.Params,\n",
        "      target_params: hk.Params,\n",
        "      online_state: hk.State,\n",
        "      target_state: hk.Params,\n",
        "      rng: jnp.ndarray,\n",
        "      inputs: Batch,\n",
        "  ) -> Tuple[jnp.ndarray, Tuple[Mapping[Text, hk.State], LogsDict]]:\n",
        "    \"\"\"Compute BYOL's loss function.\n",
        "\n",
        "    Args:\n",
        "      online_params: parameters of the online network (the loss is later\n",
        "        differentiated with respect to the online parameters).\n",
        "      target_params: parameters of the target network.\n",
        "      online_state: internal state of online network.\n",
        "      target_state: internal state of target network.\n",
        "      rng: random number generator state.\n",
        "      inputs: inputs, containing two batches of crops from the same images,\n",
        "        view1 and view2 and labels\n",
        "\n",
        "    Returns:\n",
        "      BYOL's loss, a mapping containing the online and target networks updated\n",
        "      states after processing inputs, and various logs.\n",
        "    \"\"\"\n",
        "    if self._should_transpose_images():\n",
        "      inputs = transpose_images(inputs)\n",
        "    inputs = postprocess(inputs, rng)\n",
        "    labels = inputs['labels']\n",
        "\n",
        "    online_network_out, online_state = self.forward.apply(\n",
        "        params=online_params,\n",
        "        state=online_state,\n",
        "        inputs=inputs,\n",
        "        is_training=True)\n",
        "    target_network_out, target_state = self.forward.apply(\n",
        "        params=target_params,\n",
        "        state=target_state,\n",
        "        inputs=inputs,\n",
        "        is_training=True)\n",
        "\n",
        "    # Representation loss\n",
        "\n",
        "    # The stop_gradient is not necessary as we explicitly take the gradient with\n",
        "    # respect to online parameters only in `optax.apply_updates`. We leave it to\n",
        "    # indicate that gradients are not backpropagated through the target network.\n",
        "    repr_loss = regression_loss(\n",
        "        online_network_out['prediction_view1'],\n",
        "        jax.lax.stop_gradient(target_network_out['projection_view2']))\n",
        "    repr_loss = repr_loss + regression_loss(\n",
        "        online_network_out['prediction_view2'],\n",
        "        jax.lax.stop_gradient(target_network_out['projection_view1']))\n",
        "\n",
        "    repr_loss = jnp.mean(repr_loss)\n",
        "\n",
        "    # Classification loss (with gradient flows stopped from flowing into the\n",
        "    # ResNet). This is used to provide an evaluation of the representation\n",
        "    # quality during training.\n",
        "\n",
        "    classif_loss = softmax_cross_entropy(\n",
        "        logits=online_network_out['logits_view1'],\n",
        "        labels=jax.nn.one_hot(labels, self._num_classes))\n",
        "\n",
        "    top1_correct = topk_accuracy(\n",
        "        online_network_out['logits_view1'],\n",
        "        inputs['labels'],\n",
        "        topk=1,\n",
        "    )\n",
        "\n",
        "    top5_correct = topk_accuracy(\n",
        "        online_network_out['logits_view1'],\n",
        "        inputs['labels'],\n",
        "        topk=5,\n",
        "    )\n",
        "\n",
        "    top1_acc = jnp.mean(top1_correct)\n",
        "    top5_acc = jnp.mean(top5_correct)\n",
        "\n",
        "    classif_loss = jnp.mean(classif_loss)\n",
        "    loss = repr_loss + classif_loss\n",
        "    logs = dict(\n",
        "        loss=loss,\n",
        "        repr_loss=repr_loss,\n",
        "        classif_loss=classif_loss,\n",
        "        top1_accuracy=top1_acc,\n",
        "        top5_accuracy=top5_acc,\n",
        "    )\n",
        "\n",
        "    return loss, (dict(online_state=online_state,\n",
        "                       target_state=target_state), logs)\n",
        "\n",
        "  def _should_transpose_images(self):\n",
        "    \"\"\"Should we transpose images (saves host-to-device time on TPUs).\"\"\"\n",
        "    return (self._enable_double_transpose and\n",
        "            jax.local_devices()[0].platform == 'tpu')\n",
        "\n",
        "  def _update_fn(\n",
        "      self,\n",
        "      byol_state: _ByolExperimentState,\n",
        "      global_step: jnp.ndarray,\n",
        "      rng: jnp.ndarray,\n",
        "      inputs: Batch,\n",
        "  ) -> Tuple[_ByolExperimentState, LogsDict]:\n",
        "    \"\"\"Update online and target parameters.\n",
        "\n",
        "    Args:\n",
        "      byol_state: current BYOL state.\n",
        "      global_step: current training step.\n",
        "      rng: current random number generator\n",
        "      inputs: inputs, containing two batches of crops from the same images,\n",
        "        view1 and view2 and labels\n",
        "\n",
        "    Returns:\n",
        "      Tuple containing the updated Byol state after processing the inputs, and\n",
        "      various logs.\n",
        "    \"\"\"\n",
        "    online_params = byol_state.online_params\n",
        "    target_params = byol_state.target_params\n",
        "    online_state = byol_state.online_state\n",
        "    target_state = byol_state.target_state\n",
        "    opt_state = byol_state.opt_state\n",
        "\n",
        "    # update online network\n",
        "    grad_fn = jax.grad(self.loss_fn, argnums=0, has_aux=True)\n",
        "    grads, (net_states, logs) = grad_fn(online_params, target_params,\n",
        "                                        online_state, target_state, rng, inputs)\n",
        "\n",
        "    # cross-device grad and logs reductions\n",
        "    grads = jax.tree_map(lambda v: jax.lax.pmean(v, axis_name='i'), grads)\n",
        "    logs = jax.tree_multimap(lambda x: jax.lax.pmean(x, axis_name='i'), logs)\n",
        "\n",
        "    learning_rate = learning_schedule(\n",
        "        global_step,\n",
        "        batch_size=self._batch_size,\n",
        "        total_steps=self._max_steps,\n",
        "        **self._lr_schedule_config)\n",
        "    updates, opt_state = self._optimizer(learning_rate).update(\n",
        "        grads, opt_state, online_params)\n",
        "    online_params = optax.apply_updates(online_params, updates)\n",
        "\n",
        "    # update target network\n",
        "    tau = target_ema(\n",
        "        global_step,\n",
        "        base_ema=self._base_target_ema,\n",
        "        max_steps=self._max_steps)\n",
        "    target_params = jax.tree_multimap(lambda x, y: x + (1 - tau) * (y - x),\n",
        "                                      target_params, online_params)\n",
        "    logs['tau'] = tau\n",
        "    logs['learning_rate'] = learning_rate\n",
        "    return _ByolExperimentState(\n",
        "        online_params=online_params,\n",
        "        target_params=target_params,\n",
        "        online_state=net_states['online_state'],\n",
        "        target_state=net_states['target_state'],\n",
        "        opt_state=opt_state), logs\n",
        "\n",
        "  def _make_initial_state(\n",
        "      self,\n",
        "      rng: jnp.ndarray,\n",
        "      dummy_input: Batch,\n",
        "  ) -> _ByolExperimentState:\n",
        "    \"\"\"BYOL's _ByolExperimentState initialization.\n",
        "\n",
        "    Args:\n",
        "      rng: random number generator used to initialize parameters. If working in\n",
        "        a multi device setup, this need to be a ShardedArray.\n",
        "      dummy_input: a dummy image, used to compute intermediate outputs shapes.\n",
        "\n",
        "    Returns:\n",
        "      Initial Byol state.\n",
        "    \"\"\"\n",
        "    rng_online, rng_target = jax.random.split(rng)\n",
        "\n",
        "    if self._should_transpose_images():\n",
        "      dummy_input = dataset.transpose_images(dummy_input)\n",
        "\n",
        "    # Online and target parameters are initialized using different rngs,\n",
        "    # in our experiments we did not notice a significant different with using\n",
        "    # the same rng for both.\n",
        "    online_params, online_state = self.forward.init(\n",
        "        rng_online,\n",
        "        dummy_input,\n",
        "        is_training=True,\n",
        "    )\n",
        "    target_params, target_state = self.forward.init(\n",
        "        rng_target,\n",
        "        dummy_input,\n",
        "        is_training=True,\n",
        "    )\n",
        "    opt_state = self._optimizer(0).init(online_params)\n",
        "    return _ByolExperimentState(\n",
        "        online_params=online_params,\n",
        "        target_params=target_params,\n",
        "        opt_state=opt_state,\n",
        "        online_state=online_state,\n",
        "        target_state=target_state,\n",
        "    )\n",
        "\n",
        "  def step(self, *,\n",
        "           global_step: jnp.ndarray,\n",
        "           rng: jnp.ndarray) -> Mapping[Text, np.ndarray]:\n",
        "    \"\"\"Performs a single training step.\"\"\"\n",
        "    if self._train_input is None:\n",
        "      self._initialize_train()\n",
        "\n",
        "    inputs = next(self._train_input)\n",
        "\n",
        "    self._byol_state, scalars = self.update_pmap(\n",
        "        self._byol_state,\n",
        "        global_step=global_step,\n",
        "        rng=rng,\n",
        "        inputs=inputs,\n",
        "    )\n",
        "\n",
        "    return helpers.get_first(scalars)\n",
        "\n",
        "  def save_checkpoint(self, step: int, rng: jnp.ndarray):\n",
        "    self._checkpointer.maybe_save_checkpoint(\n",
        "        self._byol_state, step=step, rng=rng, is_final=step >= self._max_steps)\n",
        "\n",
        "  def load_checkpoint(self) -> Union[Tuple[int, jnp.ndarray], None]:\n",
        "    checkpoint_data = self._checkpointer.maybe_load_checkpoint()\n",
        "    if checkpoint_data is None:\n",
        "      return None\n",
        "    self._byol_state, step, rng = checkpoint_data\n",
        "    return step, rng\n",
        "\n",
        "  def _initialize_train(self):\n",
        "    \"\"\"Initialize train.\n",
        "\n",
        "    This includes initializing the input pipeline and Byol's state.\n",
        "    \"\"\"\n",
        "    self._train_input = acme_utils.prefetch(self._build_train_input())\n",
        "\n",
        "    # Check we haven't already restored params\n",
        "    if self._byol_state is None:\n",
        "      logging.info(\n",
        "          'Initializing parameters rather than restoring from checkpoint.')\n",
        "\n",
        "      # initialize Byol and setup optimizer state\n",
        "      inputs = next(self._train_input)\n",
        "      init_byol = jax.pmap(self._make_initial_state, axis_name='i')\n",
        "\n",
        "      # Init uses the same RNG key on all hosts+devices to ensure everyone\n",
        "      # computes the same initial state and parameters.\n",
        "      init_rng = jax.random.PRNGKey(self._random_seed)\n",
        "      init_rng = helpers.bcast_local_devices(init_rng)\n",
        "\n",
        "      self._byol_state = init_byol(rng=init_rng, dummy_input=inputs)\n",
        "\n",
        "  def _build_train_input(self) -> Generator[Batch, None, None]:\n",
        "    \"\"\"Loads the (infinitely looping) dataset iterator.\"\"\"\n",
        "    num_devices = jax.device_count()\n",
        "    global_batch_size = self._batch_size\n",
        "    per_device_batch_size, ragged = divmod(global_batch_size, num_devices)\n",
        "\n",
        "    if ragged:\n",
        "      raise ValueError(\n",
        "          f'Global batch size {global_batch_size} must be divisible by '\n",
        "          f'num devices {num_devices}')\n",
        "\n",
        "    return load(\n",
        "        Split.TRAIN_AND_VALID,\n",
        "        preprocess_mode=PreprocessMode.PRETRAIN,\n",
        "        transpose=self._should_transpose_images(),\n",
        "        batch_dims=[jax.local_device_count(), per_device_batch_size])\n",
        "\n",
        "  def _eval_batch(\n",
        "      self,\n",
        "      params: hk.Params,\n",
        "      state: hk.State,\n",
        "      batch: Batch,\n",
        "  ) -> Mapping[Text, jnp.ndarray]:\n",
        "    \"\"\"Evaluates a batch.\n",
        "\n",
        "    Args:\n",
        "      params: Parameters of the model to evaluate. Typically Byol's online\n",
        "        parameters.\n",
        "      state: State of the model to evaluate. Typically Byol's online state.\n",
        "      batch: Batch of data to evaluate (must contain keys images and labels).\n",
        "\n",
        "    Returns:\n",
        "      Unreduced evaluation loss and top1 accuracy on the batch.\n",
        "    \"\"\"\n",
        "    if self._should_transpose_images():\n",
        "      batch = transpose_images(batch)\n",
        "\n",
        "    outputs, _ = self.forward.apply(params, state, batch, is_training=False)\n",
        "    logits = outputs['logits']\n",
        "    labels = hk.one_hot(batch['labels'], self._num_classes)\n",
        "    loss = softmax_cross_entropy(logits, labels, reduction=None)\n",
        "    top1_correct = topk_accuracy(logits, batch['labels'], topk=1)\n",
        "    top5_correct = topk_accuracy(logits, batch['labels'], topk=5)\n",
        "    # NOTE: Returned values will be summed and finally divided by num_samples.\n",
        "    return {\n",
        "        'eval_loss': loss,\n",
        "        'top1_accuracy': top1_correct,\n",
        "        'top5_accuracy': top5_correct,\n",
        "    }\n",
        "\n",
        "  def _eval_epoch(self, subset: Text, batch_size: int):\n",
        "    \"\"\"Evaluates an epoch.\"\"\"\n",
        "    num_samples = 0.\n",
        "    summed_scalars = None\n",
        "\n",
        "    params = get_first(self._byol_state.online_params)\n",
        "    state = get_first(self._byol_state.online_state)\n",
        "    split = Split.from_string(subset)\n",
        "\n",
        "    dataset_iterator = load(\n",
        "        split,\n",
        "        preprocess_mode=PreprocessMode.EVAL,\n",
        "        transpose=self._should_transpose_images(),\n",
        "        batch_dims=[batch_size])\n",
        "\n",
        "    for inputs in dataset_iterator:\n",
        "      num_samples += inputs['labels'].shape[0]\n",
        "      scalars = self.eval_batch_jit(params, state, inputs)\n",
        "\n",
        "      # Accumulate the sum of scalars for each step.\n",
        "      scalars = jax.tree_map(lambda x: jnp.sum(x, axis=0), scalars)\n",
        "      if summed_scalars is None:\n",
        "        summed_scalars = scalars\n",
        "      else:\n",
        "        summed_scalars = jax.tree_multimap(jnp.add, summed_scalars, scalars)\n",
        "\n",
        "    mean_scalars = jax.tree_map(lambda x: x / num_samples, summed_scalars)\n",
        "    return mean_scalars\n",
        "\n",
        "  def evaluate(self, global_step, **unused_args):\n",
        "    \"\"\"Thin wrapper around _eval_epoch.\"\"\"\n",
        "\n",
        "    global_step = np.array(get_first(global_step))\n",
        "    scalars = jax.device_get(self._eval_epoch(**self._evaluation_config))\n",
        "\n",
        "    logging.info('[Step %d] Eval scalars: %s', global_step, scalars)\n",
        "    return scalars\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Linear evaluation or fine-tuning pipeline.\n",
        "\n",
        "Use this experiment to evaluate a checkpoint from byol_experiment.\n",
        "\"\"\"\n",
        "\n",
        "import functools\n",
        "from typing import Any, Generator, Mapping, NamedTuple, Optional, Text, Tuple, Union\n",
        "\n",
        "from absl import logging\n",
        "from acme.jax import utils as acme_utils\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "\n",
        "#from byol.utils import checkpointing\n",
        "#from byol.utils import dataset\n",
        "#from byol.utils import helpers\n",
        "#from byol.utils import networks\n",
        "#from byol.utils import schedules\n",
        "\n",
        "# Type declarations.\n",
        "OptState = Tuple[optax.TraceState, optax.ScaleByScheduleState, optax.ScaleState]\n",
        "LogsDict = Mapping[Text, jnp.ndarray]\n",
        "\n",
        "\n",
        "class _EvalExperimentState(NamedTuple):\n",
        "  backbone_params: hk.Params\n",
        "  classif_params: hk.Params\n",
        "  backbone_state: hk.State\n",
        "  backbone_opt_state: Union[None, OptState]\n",
        "  classif_opt_state: OptState\n",
        "\n",
        "\n",
        "class EvalExperiment:\n",
        "  \"\"\"Linear evaluation experiment.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      random_seed: int,\n",
        "      num_classes: int,\n",
        "      batch_size: int,\n",
        "      max_steps: int,\n",
        "      enable_double_transpose: bool,\n",
        "      checkpoint_to_evaluate: Optional[Text],\n",
        "      allow_train_from_scratch: bool,\n",
        "      freeze_backbone: bool,\n",
        "      network_config: Mapping[Text, Any],\n",
        "      optimizer_config: Mapping[Text, Any],\n",
        "      lr_schedule_config: Mapping[Text, Any],\n",
        "      evaluation_config: Mapping[Text, Any],\n",
        "      checkpointing_config: Mapping[Text, Any]):\n",
        "    \"\"\"Constructs the experiment.\n",
        "\n",
        "    Args:\n",
        "      random_seed: the random seed to use when initializing network weights.\n",
        "      num_classes: the number of classes; used for the online evaluation.\n",
        "      batch_size: the total batch size; should be a multiple of the number of\n",
        "        available accelerators.\n",
        "      max_steps: the number of training steps; used for the lr/target network\n",
        "        ema schedules.\n",
        "      enable_double_transpose: see dataset.py; only has effect on TPU.\n",
        "      checkpoint_to_evaluate: the path to the checkpoint to evaluate.\n",
        "      allow_train_from_scratch: whether to allow training without specifying a\n",
        "        checkpoint to evaluate (training from scratch).\n",
        "      freeze_backbone: whether the backbone resnet should remain frozen (linear\n",
        "        evaluation) or be trainable (fine-tuning).\n",
        "      network_config: the configuration for the network.\n",
        "      optimizer_config: the configuration for the optimizer.\n",
        "      lr_schedule_config: the configuration for the learning rate schedule.\n",
        "      evaluation_config: the evaluation configuration.\n",
        "      checkpointing_config: the configuration for checkpointing.\n",
        "    \"\"\"\n",
        "\n",
        "    self._random_seed = random_seed\n",
        "    self._enable_double_transpose = enable_double_transpose\n",
        "    self._num_classes = num_classes\n",
        "    self._lr_schedule_config = lr_schedule_config\n",
        "    self._batch_size = batch_size\n",
        "    self._max_steps = max_steps\n",
        "    self._checkpoint_to_evaluate = checkpoint_to_evaluate\n",
        "    self._allow_train_from_scratch = allow_train_from_scratch\n",
        "    self._freeze_backbone = freeze_backbone\n",
        "    self._optimizer_config = optimizer_config\n",
        "    self._evaluation_config = evaluation_config\n",
        "\n",
        "    # Checkpointed experiment state.\n",
        "    self._experiment_state = None\n",
        "\n",
        "    # Input pipelines.\n",
        "    self._train_input = None\n",
        "    self._eval_input = None\n",
        "\n",
        "    backbone_fn = functools.partial(self._backbone_fn, **network_config)\n",
        "    self.forward_backbone = hk.without_apply_rng(\n",
        "        hk.transform_with_state(backbone_fn))\n",
        "    self.forward_classif = hk.without_apply_rng(hk.transform(self._classif_fn))\n",
        "    self.update_pmap = jax.pmap(self._update_func, axis_name='i')\n",
        "    self.eval_batch_jit = jax.jit(self._eval_batch)\n",
        "\n",
        "    self._is_backbone_training = not self._freeze_backbone\n",
        "\n",
        "    self._checkpointer = Checkpointer(**checkpointing_config)\n",
        "\n",
        "  def _should_transpose_images(self):\n",
        "    \"\"\"Should we transpose images (saves host-to-device time on TPUs).\"\"\"\n",
        "    return (self._enable_double_transpose and\n",
        "            jax.local_devices()[0].platform == 'tpu')\n",
        "\n",
        "  def _backbone_fn(\n",
        "      self,\n",
        "      inputs: Batch,\n",
        "      encoder_class: Text,\n",
        "      encoder_config: Mapping[Text, Any],\n",
        "      bn_decay_rate: float,\n",
        "      is_training: bool,\n",
        "  ) -> jnp.ndarray:\n",
        "    \"\"\"Forward of the encoder (backbone).\"\"\"\n",
        "    bn_config = {'decay_rate': bn_decay_rate}\n",
        "    encoder = getattr(networks, encoder_class)\n",
        "    model = encoder(\n",
        "        None,\n",
        "        bn_config=bn_config,\n",
        "        **encoder_config)\n",
        "\n",
        "    if self._should_transpose_images():\n",
        "      inputs = transpose_images(inputs)\n",
        "    images = normalize_images(inputs['images'])\n",
        "    return model(images, is_training=is_training)\n",
        "\n",
        "  def _classif_fn(\n",
        "      self,\n",
        "      embeddings: jnp.ndarray,\n",
        "  ) -> jnp.ndarray:\n",
        "    classifier = hk.Linear(output_size=self._num_classes)\n",
        "    return classifier(embeddings)\n",
        "\n",
        "  #  _             _\n",
        "  # | |_ _ __ __ _(_)_ __\n",
        "  # | __| '__/ _` | | '_ \\\n",
        "  # | |_| | | (_| | | | | |\n",
        "  #  \\__|_|  \\__,_|_|_| |_|\n",
        "  #\n",
        "\n",
        "  def step(self, *,\n",
        "           global_step: jnp.ndarray,\n",
        "           rng: jnp.ndarray) -> Mapping[Text, np.ndarray]:\n",
        "    \"\"\"Performs a single training step.\"\"\"\n",
        "\n",
        "    if self._train_input is None:\n",
        "      self._initialize_train(rng)\n",
        "\n",
        "    inputs = next(self._train_input)\n",
        "    self._experiment_state, scalars = self.update_pmap(\n",
        "        self._experiment_state, global_step, inputs)\n",
        "\n",
        "    scalars = get_first(scalars)\n",
        "    return scalars\n",
        "\n",
        "  def save_checkpoint(self, step: int, rng: jnp.ndarray):\n",
        "    self._checkpointer.maybe_save_checkpoint(\n",
        "        self._experiment_state, step=step, rng=rng,\n",
        "        is_final=step >= self._max_steps)\n",
        "\n",
        "  def load_checkpoint(self) -> Union[Tuple[int, jnp.ndarray], None]:\n",
        "    checkpoint_data = self._checkpointer.maybe_load_checkpoint()\n",
        "    if checkpoint_data is None:\n",
        "      return None\n",
        "    self._experiment_state, step, rng = checkpoint_data\n",
        "    return step, rng\n",
        "\n",
        "  def _initialize_train(self, rng):\n",
        "    \"\"\"BYOL's _ExperimentState initialization.\n",
        "\n",
        "    Args:\n",
        "      rng: random number generator used to initialize parameters. If working in\n",
        "        a multi device setup, this need to be a ShardedArray.\n",
        "      dummy_input: a dummy image, used to compute intermediate outputs shapes.\n",
        "\n",
        "    Returns:\n",
        "      Initial EvalExperiment state.\n",
        "\n",
        "    Raises:\n",
        "      RuntimeError: invalid or empty checkpoint.\n",
        "    \"\"\"\n",
        "    self._train_input = acme_utils.prefetch(self._build_train_input())\n",
        "\n",
        "    # Check we haven't already restored params\n",
        "    if self._experiment_state is None:\n",
        "\n",
        "      inputs = next(self._train_input)\n",
        "\n",
        "      if self._checkpoint_to_evaluate is not None:\n",
        "        # Load params from checkpoint\n",
        "        checkpoint_data = load_checkpoint(\n",
        "            self._checkpoint_to_evaluate)\n",
        "        if checkpoint_data is None:\n",
        "          raise RuntimeError('Invalid checkpoint.')\n",
        "        backbone_params = checkpoint_data['experiment_state'].online_params\n",
        "        backbone_state = checkpoint_data['experiment_state'].online_state\n",
        "        backbone_params = bcast_local_devices(backbone_params)\n",
        "        backbone_state = bcast_local_devices(backbone_state)\n",
        "      else:\n",
        "        if not self._allow_train_from_scratch:\n",
        "          raise ValueError(\n",
        "              'No checkpoint specified, but `allow_train_from_scratch` '\n",
        "              'set to False')\n",
        "        # Initialize with random parameters\n",
        "        logging.info(\n",
        "            'No checkpoint specified, initializing the networks from scratch '\n",
        "            '(dry run mode)')\n",
        "        backbone_params, backbone_state = jax.pmap(\n",
        "            functools.partial(self.forward_backbone.init, is_training=True),\n",
        "            axis_name='i')(rng=rng, inputs=inputs)\n",
        "\n",
        "      init_experiment = jax.pmap(self._make_initial_state, axis_name='i')\n",
        "\n",
        "      # Init uses the same RNG key on all hosts+devices to ensure everyone\n",
        "      # computes the same initial state and parameters.\n",
        "      init_rng = jax.random.PRNGKey(self._random_seed)\n",
        "      init_rng = bcast_local_devices(init_rng)\n",
        "      self._experiment_state = init_experiment(\n",
        "          rng=init_rng,\n",
        "          dummy_input=inputs,\n",
        "          backbone_params=backbone_params,\n",
        "          backbone_state=backbone_state)\n",
        "\n",
        "      # Clear the backbone optimizer's state when the backbone is frozen.\n",
        "      if self._freeze_backbone:\n",
        "        self._experiment_state = _EvalExperimentState(\n",
        "            backbone_params=self._experiment_state.backbone_params,\n",
        "            classif_params=self._experiment_state.classif_params,\n",
        "            backbone_state=self._experiment_state.backbone_state,\n",
        "            backbone_opt_state=None,\n",
        "            classif_opt_state=self._experiment_state.classif_opt_state,\n",
        "        )\n",
        "\n",
        "  def _make_initial_state(\n",
        "      self,\n",
        "      rng: jnp.ndarray,\n",
        "      dummy_input: Batch,\n",
        "      backbone_params: hk.Params,\n",
        "      backbone_state: hk.Params,\n",
        "  ) -> _EvalExperimentState:\n",
        "    \"\"\"_EvalExperimentState initialization.\"\"\"\n",
        "\n",
        "    # Initialize the backbone params\n",
        "    # Always create the batchnorm weights (is_training=True), they will be\n",
        "    # overwritten when loading the checkpoint.\n",
        "    embeddings, _ = self.forward_backbone.apply(\n",
        "        backbone_params, backbone_state, dummy_input, is_training=True)\n",
        "    backbone_opt_state = self._optimizer(0.).init(backbone_params)\n",
        "\n",
        "    # Initialize the classifier params and optimizer_state\n",
        "    classif_params = self.forward_classif.init(rng, embeddings)\n",
        "    classif_opt_state = self._optimizer(0.).init(classif_params)\n",
        "\n",
        "    return _EvalExperimentState(\n",
        "        backbone_params=backbone_params,\n",
        "        classif_params=classif_params,\n",
        "        backbone_state=backbone_state,\n",
        "        backbone_opt_state=backbone_opt_state,\n",
        "        classif_opt_state=classif_opt_state,\n",
        "    )\n",
        "\n",
        "  def _build_train_input(self) -> Generator[Batch, None, None]:\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    num_devices = jax.device_count()\n",
        "    global_batch_size = self._batch_size\n",
        "    per_device_batch_size, ragged = divmod(global_batch_size, num_devices)\n",
        "\n",
        "    if ragged:\n",
        "      raise ValueError(\n",
        "          f'Global batch size {global_batch_size} must be divisible by '\n",
        "          f'num devices {num_devices}')\n",
        "\n",
        "    return load(\n",
        "        Split.TRAIN_AND_VALID,\n",
        "        preprocess_mode=PreprocessMode.LINEAR_TRAIN,\n",
        "        transpose=self._should_transpose_images(),\n",
        "        batch_dims=[jax.local_device_count(), per_device_batch_size])\n",
        "\n",
        "  def _optimizer(self, learning_rate: float):\n",
        "    \"\"\"Build optimizer from config.\"\"\"\n",
        "    return optax.sgd(learning_rate, **self._optimizer_config)\n",
        "\n",
        "  def _loss_fn(\n",
        "      self,\n",
        "      backbone_params: hk.Params,\n",
        "      classif_params: hk.Params,\n",
        "      backbone_state: hk.State,\n",
        "      inputs: Batch,\n",
        "  ) -> Tuple[jnp.ndarray, Tuple[jnp.ndarray, hk.State]]:\n",
        "    \"\"\"Compute the classification loss function.\n",
        "\n",
        "    Args:\n",
        "      backbone_params: parameters of the encoder network.\n",
        "      classif_params: parameters of the linear classifier.\n",
        "      backbone_state: internal state of encoder network.\n",
        "      inputs: inputs, containing `images` and `labels`.\n",
        "\n",
        "    Returns:\n",
        "      The classification loss and various logs.\n",
        "    \"\"\"\n",
        "    embeddings, backbone_state = self.forward_backbone.apply(\n",
        "        backbone_params,\n",
        "        backbone_state,\n",
        "        inputs,\n",
        "        is_training=not self._freeze_backbone)\n",
        "\n",
        "    logits = self.forward_classif.apply(classif_params, embeddings)\n",
        "    labels = hk.one_hot(inputs['labels'], self._num_classes)\n",
        "    loss = softmax_cross_entropy(logits, labels, reduction='mean')\n",
        "    scaled_loss = loss / jax.device_count()\n",
        "\n",
        "    return scaled_loss, (loss, backbone_state)\n",
        "\n",
        "  def _update_func(\n",
        "      self,\n",
        "      experiment_state: _EvalExperimentState,\n",
        "      global_step: jnp.ndarray,\n",
        "      inputs: Batch,\n",
        "  ) -> Tuple[_EvalExperimentState, LogsDict]:\n",
        "    \"\"\"Applies an update to parameters and returns new state.\"\"\"\n",
        "    # This function computes the gradient of the first output of loss_fn and\n",
        "    # passes through the other arguments unchanged.\n",
        "\n",
        "    # Gradient of the first output of _loss_fn wrt the backbone (arg 0) and the\n",
        "    # classifier parameters (arg 1). The auxiliary outputs are returned as-is.\n",
        "    grad_loss_fn = jax.grad(self._loss_fn, has_aux=True, argnums=(0, 1))\n",
        "\n",
        "    grads, aux_outputs = grad_loss_fn(\n",
        "        experiment_state.backbone_params,\n",
        "        experiment_state.classif_params,\n",
        "        experiment_state.backbone_state,\n",
        "        inputs,\n",
        "    )\n",
        "    backbone_grads, classifier_grads = grads\n",
        "    train_loss, new_backbone_state = aux_outputs\n",
        "    classifier_grads = jax.lax.psum(classifier_grads, axis_name='i')\n",
        "\n",
        "    # Compute the decayed learning rate\n",
        "    learning_rate = learning_schedule(\n",
        "        global_step,\n",
        "        batch_size=self._batch_size,\n",
        "        total_steps=self._max_steps,\n",
        "        **self._lr_schedule_config)\n",
        "\n",
        "    # Compute and apply updates via our optimizer.\n",
        "    classif_updates, new_classif_opt_state = \\\n",
        "        self._optimizer(learning_rate).update(\n",
        "            classifier_grads,\n",
        "            experiment_state.classif_opt_state)\n",
        "\n",
        "    new_classif_params = optax.apply_updates(experiment_state.classif_params,\n",
        "                                             classif_updates)\n",
        "\n",
        "    if self._freeze_backbone:\n",
        "      del backbone_grads, new_backbone_state  # Unused\n",
        "      # The backbone is not updated.\n",
        "      new_backbone_params = experiment_state.backbone_params\n",
        "      new_backbone_opt_state = None\n",
        "      new_backbone_state = experiment_state.backbone_state\n",
        "    else:\n",
        "      backbone_grads = jax.lax.psum(backbone_grads, axis_name='i')\n",
        "\n",
        "      # Compute and apply updates via our optimizer.\n",
        "      backbone_updates, new_backbone_opt_state = \\\n",
        "          self._optimizer(learning_rate).update(\n",
        "              backbone_grads,\n",
        "              experiment_state.backbone_opt_state)\n",
        "\n",
        "      new_backbone_params = optax.apply_updates(\n",
        "          experiment_state.backbone_params, backbone_updates)\n",
        "\n",
        "    experiment_state = _EvalExperimentState(\n",
        "        new_backbone_params,\n",
        "        new_classif_params,\n",
        "        new_backbone_state,\n",
        "        new_backbone_opt_state,\n",
        "        new_classif_opt_state,\n",
        "    )\n",
        "\n",
        "    # Scalars to log (note: we log the mean across all hosts/devices).\n",
        "    scalars = {'train_loss': train_loss}\n",
        "    scalars = jax.lax.pmean(scalars, axis_name='i')\n",
        "\n",
        "    return experiment_state, scalars\n",
        "\n",
        "  #                  _\n",
        "  #   _____   ____ _| |\n",
        "  #  / _ \\ \\ / / _` | |\n",
        "  # |  __/\\ V / (_| | |\n",
        "  #  \\___| \\_/ \\__,_|_|\n",
        "  #\n",
        "\n",
        "  def evaluate(self, global_step, **unused_args):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "\n",
        "    global_step = np.array(get_first(global_step))\n",
        "    scalars = jax.device_get(self._eval_epoch(**self._evaluation_config))\n",
        "\n",
        "    logging.info('[Step %d] Eval scalars: %s', global_step, scalars)\n",
        "    return scalars\n",
        "\n",
        "  def _eval_batch(\n",
        "      self,\n",
        "      backbone_params: hk.Params,\n",
        "      classif_params: hk.Params,\n",
        "      backbone_state: hk.State,\n",
        "      inputs: Batch,\n",
        "  ) -> LogsDict:\n",
        "    \"\"\"Evaluates a batch.\"\"\"\n",
        "    embeddings, backbone_state = self.forward_backbone.apply(\n",
        "        backbone_params, backbone_state, inputs, is_training=False)\n",
        "    logits = self.forward_classif.apply(classif_params, embeddings)\n",
        "    labels = hk.one_hot(inputs['labels'], self._num_classes)\n",
        "    loss = softmax_cross_entropy(logits, labels, reduction=None)\n",
        "    top1_correct = topk_accuracy(logits, inputs['labels'], topk=1)\n",
        "    top5_correct = topk_accuracy(logits, inputs['labels'], topk=5)\n",
        "    # NOTE: Returned values will be summed and finally divided by num_samples.\n",
        "    return {\n",
        "        'eval_loss': loss,\n",
        "        'top1_accuracy': top1_correct,\n",
        "        'top5_accuracy': top5_correct\n",
        "    }\n",
        "\n",
        "  def _eval_epoch(self, subset: Text, batch_size: int):\n",
        "    \"\"\"Evaluates an epoch.\"\"\"\n",
        "    num_samples = 0.\n",
        "    summed_scalars = None\n",
        "\n",
        "    backbone_params = get_first(self._experiment_state.backbone_params)\n",
        "    classif_params = get_first(self._experiment_state.classif_params)\n",
        "    backbone_state = get_first(self._experiment_state.backbone_state)\n",
        "    split = Split.from_string(subset)\n",
        "\n",
        "    dataset_iterator = load(\n",
        "        split,\n",
        "        preprocess_mode=PreprocessMode.EVAL,\n",
        "        transpose=self._should_transpose_images(),\n",
        "        batch_dims=[batch_size])\n",
        "\n",
        "    for inputs in dataset_iterator:\n",
        "      num_samples += inputs['labels'].shape[0]\n",
        "      scalars = self.eval_batch_jit(\n",
        "          backbone_params,\n",
        "          classif_params,\n",
        "          backbone_state,\n",
        "          inputs,\n",
        "      )\n",
        "\n",
        "      # Accumulate the sum of scalars for each step.\n",
        "      scalars = jax.tree_map(lambda x: jnp.sum(x, axis=0), scalars)\n",
        "      if summed_scalars is None:\n",
        "        summed_scalars = scalars\n",
        "      else:\n",
        "        summed_scalars = jax.tree_multimap(jnp.add, summed_scalars, scalars)\n",
        "\n",
        "    mean_scalars = jax.tree_map(lambda x: x / num_samples, summed_scalars)\n",
        "    return mean_scalars\n"
      ],
      "metadata": {
        "id": "1-jWvCVZ_lkc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Config file for BYOL experiment.\"\"\"\n",
        "\n",
        "#from byol.utils import dataset\n",
        "\n",
        "\n",
        "# Preset values for certain number of training epochs.\n",
        "_LR_PRESETS = {40: 0.45, 100: 0.45, 300: 0.3, 1000: 0.2}\n",
        "_WD_PRESETS = {40: 1e-6, 100: 1e-6, 300: 1e-6, 1000: 1.5e-6}\n",
        "_EMA_PRESETS = {40: 0.97, 100: 0.99, 300: 0.99, 1000: 0.996}\n",
        "\n",
        "\n",
        "def get_config_byol(num_epochs: int, batch_size: int):\n",
        "  \"\"\"Return config object, containing all hyperparameters for training.\"\"\"\n",
        "  train_images_per_epoch = Split.TRAIN_AND_VALID.num_examples\n",
        "\n",
        "  assert num_epochs in [40, 100, 300, 1000]\n",
        "\n",
        "  config = dict(\n",
        "      random_seed=0,\n",
        "      num_classes=1000,\n",
        "      batch_size=batch_size,\n",
        "      max_steps=num_epochs * train_images_per_epoch // batch_size,\n",
        "      enable_double_transpose=True,\n",
        "      base_target_ema=_EMA_PRESETS[num_epochs],\n",
        "      network_config=dict(\n",
        "          projector_hidden_size=4096,\n",
        "          projector_output_size=256,\n",
        "          predictor_hidden_size=4096,\n",
        "          encoder_class='ResNet18',  # Should match a class in utils/networks.\n",
        "          encoder_config=dict(\n",
        "              resnet_v2=False,\n",
        "              width_multiplier=1),\n",
        "          bn_config={\n",
        "              'decay_rate': .9,\n",
        "              'eps': 1e-5,\n",
        "              # Accumulate batchnorm statistics across devices.\n",
        "              # This should be equal to the `axis_name` argument passed\n",
        "              # to jax.pmap.\n",
        "              'cross_replica_axis': 'i',\n",
        "              'create_scale': True,\n",
        "              'create_offset': True,\n",
        "          }),\n",
        "      optimizer_config=dict(\n",
        "          weight_decay=_WD_PRESETS[num_epochs],\n",
        "          eta=1e-3,\n",
        "          momentum=.9,\n",
        "      ),\n",
        "      lr_schedule_config=dict(\n",
        "          base_learning_rate=_LR_PRESETS[num_epochs],\n",
        "          warmup_steps=10 * train_images_per_epoch // batch_size,\n",
        "      ),\n",
        "      evaluation_config=dict(\n",
        "          subset='test',\n",
        "          batch_size=100,\n",
        "      ),\n",
        "      checkpointing_config=dict(\n",
        "          use_checkpointing=True,\n",
        "          checkpoint_dir='/tmp/byol',\n",
        "          save_checkpoint_interval=300,\n",
        "          filename='pretrain.pkl'\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  return config\n"
      ],
      "metadata": {
        "id": "oZXy15jOAGvN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Config file for evaluation experiment.\"\"\"\n",
        "\n",
        "from typing import Text\n",
        "\n",
        "#from byol.utils import dataset\n",
        "\n",
        "\n",
        "def get_config_eval(checkpoint_to_evaluate: Text, batch_size: int):\n",
        "  \"\"\"Return config object for training.\"\"\"\n",
        "  train_images_per_epoch = Split.TRAIN_AND_VALID.num_examples\n",
        "\n",
        "  config = dict(\n",
        "      random_seed=0,\n",
        "      enable_double_transpose=True,\n",
        "      max_steps=80 * train_images_per_epoch // batch_size,\n",
        "      num_classes=1000,\n",
        "      batch_size=batch_size,\n",
        "      checkpoint_to_evaluate=checkpoint_to_evaluate,\n",
        "      # If True, allows training without loading a checkpoint.\n",
        "      allow_train_from_scratch=False,\n",
        "      # Whether the backbone should be frozen (linear evaluation) or\n",
        "      # trainable (fine-tuning).\n",
        "      freeze_backbone=True,\n",
        "      optimizer_config=dict(\n",
        "          momentum=0.9,\n",
        "          nesterov=True,\n",
        "      ),\n",
        "      lr_schedule_config=dict(\n",
        "          base_learning_rate=0.2,\n",
        "          warmup_steps=0,\n",
        "      ),\n",
        "      network_config=dict(  # Should match the evaluated checkpoint\n",
        "          encoder_class='ResNet18',  # Should match a class in utils/networks.\n",
        "          encoder_config=dict(\n",
        "              resnet_v2=False,\n",
        "              width_multiplier=1),\n",
        "          bn_decay_rate=0.9,\n",
        "      ),\n",
        "      evaluation_config=dict(\n",
        "          subset='test',\n",
        "          batch_size=100,\n",
        "      ),\n",
        "      checkpointing_config=dict(\n",
        "          use_checkpointing=True,\n",
        "          checkpoint_dir='/tmp/byol',\n",
        "          save_checkpoint_interval=300,\n",
        "          filename='linear-eval.pkl'\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  return config\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hhSF2NB3ANS6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Eval Loop"
      ],
      "metadata": {
        "id": "vQo0brXb_1b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 DeepMind Technologies Limited.\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Training and evaluation loops for an experiment.\"\"\"\n",
        "\n",
        "import time\n",
        "from typing import Any, Mapping, Text, Type, Union\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "import jax\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='BYOL PARAMETERS')\n",
        "#from byol import byol_experiment\n",
        "#from byol import eval_experiment\n",
        "#from byol.configs import byol as byol_config\n",
        "#from byol.configs import eval as eval_config\n",
        "\"\"\"\n",
        "flags.DEFINE_string('experiment_mode',\n",
        "                    'pretrain', 'The experiment, pretrain or linear-eval')\n",
        "flags.DEFINE_string('worker_mode', 'train', 'The mode, train or eval')\n",
        "flags.DEFINE_string('worker_tpu_driver', '', 'The tpu driver to use')\n",
        "flags.DEFINE_integer('pretrain_epochs', 1000, 'Number of pre-training epochs')\n",
        "flags.DEFINE_integer('batch_size', 4096, 'Total batch size')\n",
        "flags.DEFINE_string('checkpoint_root', '/tmp/byol',\n",
        "                    'The directory to save checkpoints to.')\n",
        "flags.DEFINE_integer('log_tensors_interval', 60, 'Log tensors every n seconds.')\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\"\"\"\n",
        "parser.add_argument('-j', '--workers', default=32, type=int, metavar='N',\n",
        "                    help='number of data loading workers (default: 32)')\n",
        "parser.add_argument('--pretrain-epochs', default=1000, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "parser.add_argument('-b', '--batch-size', default=4096, type=int,\n",
        "                    metavar='N',\n",
        "                    help='mini-batch size (default: 4096), this is the total '\n",
        "                         'batch size of all GPUs on the current node when '\n",
        "                         'using Data Parallel or Distributed Data Parallel')\n",
        "parser.add_argument('--log-tensors-interval', default=60, type=int,\n",
        "                    metavar='LTI', help='Log tensors every n seconds.')\n",
        "parser.add_argument('--experiment-mode', default='pretrain', type=str,\n",
        "                    help='The experiment, pretrain or linear-eval')\n",
        "parser.add_argument('--worker-mode', default='train', type=str,\n",
        "                    help='path to latest checkpoint (default: none)')\n",
        "'The mode, train or eval'\n",
        "parser.add_argument('--worker-tpu-driver', default='', type=str,\n",
        "                    help='The tpu driver to use')\n",
        "parser.add_argument('--checkpoint-root', default='/tmp/byol', type=str,\n",
        "                    help='The directory to save checkpoints to.')\n",
        "\n",
        "FLAGS, unknown = parser.parse_known_args()\n",
        "\"\"\"\n",
        "Experiment = Union[\n",
        "    Type[byol_experiment.ByolExperiment],\n",
        "    Type[eval_experiment.EvalExperiment]]\n",
        "\"\"\"\n",
        "Experiment = Union[\n",
        "    Type[ByolExperiment],\n",
        "    Type[EvalExperiment]]\n",
        "\n",
        "def train_loop(experiment_class: Experiment, config: Mapping[Text, Any]):\n",
        "  \"\"\"The main training loop.\n",
        "\n",
        "  This loop periodically saves a checkpoint to be evaluated in the eval_loop.\n",
        "\n",
        "  Args:\n",
        "    experiment_class: the constructor for the experiment (either byol_experiment\n",
        "    or eval_experiment).\n",
        "    config: the experiment config.\n",
        "  \"\"\"\n",
        "  experiment = experiment_class(**config)\n",
        "  rng = jax.random.PRNGKey(0)\n",
        "  step = 0\n",
        "\n",
        "  host_id = jax.host_id()\n",
        "  last_logging = time.time()\n",
        "  if config['checkpointing_config']['use_checkpointing']:\n",
        "    checkpoint_data = experiment.load_checkpoint()\n",
        "    if checkpoint_data is None:\n",
        "      step = 0\n",
        "    else:\n",
        "      step, rng = checkpoint_data\n",
        "\n",
        "  local_device_count = jax.local_device_count()\n",
        "  while step < config['max_steps']:\n",
        "    step_rng, rng = tuple(jax.random.split(rng))\n",
        "    # Broadcast the random seeds across the devices\n",
        "    step_rng_device = jax.random.split(step_rng, num=jax.device_count())\n",
        "    step_rng_device = step_rng_device[\n",
        "        host_id * local_device_count:(host_id + 1) * local_device_count]\n",
        "    step_device = np.broadcast_to(step, [local_device_count])\n",
        "\n",
        "    # Perform a training step and get scalars to log.\n",
        "    scalars = experiment.step(global_step=step_device, rng=step_rng_device)\n",
        "\n",
        "    # Checkpointing and logging.\n",
        "    if config['checkpointing_config']['use_checkpointing']:\n",
        "      experiment.save_checkpoint(step, rng)\n",
        "      current_time = time.time()\n",
        "      if current_time - last_logging > FLAGS.log_tensors_interval:\n",
        "        logging.info('Step %d: %s', step, scalars)\n",
        "        last_logging = current_time\n",
        "    step += 1\n",
        "  logging.info('Saving final checkpoint')\n",
        "  logging.info('Step %d: %s', step, scalars)\n",
        "  experiment.save_checkpoint(step, rng)\n",
        "\n",
        "\n",
        "def eval_loop(experiment_class: Experiment, config: Mapping[Text, Any]):\n",
        "  \"\"\"The main evaluation loop.\n",
        "\n",
        "  This loop periodically loads a checkpoint and evaluates its performance on the\n",
        "  test set, by calling experiment.evaluate.\n",
        "\n",
        "  Args:\n",
        "    experiment_class: the constructor for the experiment (either byol_experiment\n",
        "    or eval_experiment).\n",
        "    config: the experiment config.\n",
        "  \"\"\"\n",
        "  experiment = experiment_class(**config)\n",
        "  last_evaluated_step = -1\n",
        "  while True:\n",
        "    checkpoint_data = experiment.load_checkpoint()\n",
        "    if checkpoint_data is None:\n",
        "      logging.info('No checkpoint found. Waiting for 10s.')\n",
        "      time.sleep(10)\n",
        "      continue\n",
        "    step, _ = checkpoint_data\n",
        "    if step <= last_evaluated_step:\n",
        "      logging.info('Checkpoint at step %d already evaluated, waiting.', step)\n",
        "      time.sleep(10)\n",
        "      continue\n",
        "    host_id = jax.host_id()\n",
        "    local_device_count = jax.local_device_count()\n",
        "    step_device = np.broadcast_to(step, [local_device_count])\n",
        "    scalars = experiment.evaluate(global_step=step_device)\n",
        "    if host_id == 0:  # Only perform logging in one host.\n",
        "      logging.info('Evaluation at step %d: %s', step, scalars)\n",
        "    last_evaluated_step = step\n",
        "    if last_evaluated_step >= config['max_steps']:\n",
        "      return\n",
        "\n"
      ],
      "metadata": {
        "id": "WjoPa6AE-zki"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if FLAGS.worker_tpu_driver:\n",
        "  jax.config.update('jax_xla_backend', 'tpu_driver')\n",
        "  jax.config.update('jax_backend_target', FLAGS.worker_tpu_driver)\n",
        "  logging.info('Backend: %s %r', FLAGS.worker_tpu_driver, jax.devices())\n",
        "\n",
        "if FLAGS.experiment_mode == 'pretrain':\n",
        "  experiment_class = ByolExperiment\n",
        "  config = get_config_byol(FLAGS.pretrain_epochs, FLAGS.batch_size)\n",
        "elif FLAGS.experiment_mode == 'linear-eval':\n",
        "  experiment_class = EvalExperiment\n",
        "  config = eval_config.get_config_eval(f'{FLAGS.checkpoint_root}/pretrain.pkl',\n",
        "                                  FLAGS.batch_size)\n",
        "else:\n",
        "  raise ValueError(f'Unknown experiment mode: {FLAGS.experiment_mode}')\n",
        "config['checkpointing_config']['checkpoint_dir'] = FLAGS.checkpoint_root  # pytype: disable=unsupported-operands  # dict-kwargs\n"
      ],
      "metadata": {
        "id": "-M0fqCMv_U5g"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if FLAGS.worker_mode == 'train':\n",
        "  train_loop(experiment_class, config)\n",
        "elif FLAGS.worker_mode == 'eval':\n",
        "  eval_loop(experiment_class, config)"
      ],
      "metadata": {
        "id": "8r_EQclhxObf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}